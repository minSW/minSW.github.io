<!DOCTYPE html><html lang="ko"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> &#039;Spark The Definitive Guide&#039; 2ì¥ - ìŠ¤íŒŒí¬ ì°ì–´ë¨¹ê¸° Â· Look out</title><meta name="description" content="&amp;#039;Spark The Definitive Guide&amp;#039; 2ì¥ - ìŠ¤íŒŒí¬ ì°ì–´ë¨¹ê¸° - Lukka Min"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/cover.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"><link rel="search" type="application/opensearchdescription+xml" href="https://minsw.github.io/atom.xml" title="Look out"><script src="//code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/feed.xml" title="Look out" type="application/atom+xml">
</head><body><div class="wrap"><header><a class="logo-link" href="/"><img src="/cover.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a class="nav-list-link" href="/" target="_self">BLOG</a></li><li class="nav-list-item"><a class="nav-list-link" href="/archives/" target="_self">ARCHIVE</a></li><li class="nav-list-item"><a class="nav-list-link" href="/tags/" target="_self">TAG</a></li><li class="nav-list-item"><a class="nav-list-link" href="https://github.com/minSW" target="_blank">GITHUB</a></li></ul></header><main class="container"></main><div class="post"><article class="post-block"><h1 class="post-title">&#039;Spark The Definitive Guide&#039; 2ì¥ - ìŠ¤íŒŒí¬ ì°ì–´ë¨¹ê¸°</h1><div class="post-info">2021ë…„ 1ì›” 24ì¼<span class="categories"><i class="fa fa-bookmark" aria-hidden="true"></i></span><a class="post-category" href="/categories/spark/">#spark</a></div><div class="post-content"><img src="https://user-images.githubusercontent.com/26691216/105627228-e66e3200-5e78-11eb-9ea6-2e3662267b7a.jpg" width=200 />
<center> ë„ì»¤ ì´ë¯¸ì§€ ì‚¬ìš©ì‹œ Zeppelinì— ì˜ˆì œ ì½”ë“œê°€ ìˆë‹¤ <br/>
ë‚˜ì²˜ëŸ¼ ì‹œë ¥ ê²€ì‚¬&íƒ€ì ì—°ìŠµ í•˜ëŠë¼ ì§„ë¹¼ì§€ë§ê³  Chapter2ëŠ” ê·¸ëƒ¥ ì˜ˆì œ ì½”ë“œë¥¼ ì“°ë„ë¡ í•˜ì... </center>


<center><h2>_ _ _</h2></center>

<br/>

<hr>
<h1 id="CHAPTER-2-ìŠ¤íŒŒí¬-ê°„ë‹¨íˆ-ì‚´í´ë³´ê¸°"><a href="#CHAPTER-2-ìŠ¤íŒŒí¬-ê°„ë‹¨íˆ-ì‚´í´ë³´ê¸°" class="headerlink" title="CHAPTER 2 ìŠ¤íŒŒí¬ ê°„ë‹¨íˆ ì‚´í´ë³´ê¸°"></a>CHAPTER 2 ìŠ¤íŒŒí¬ ê°„ë‹¨íˆ ì‚´í´ë³´ê¸°</h1><p>DataFrame, SQL ì„ ì‚¬ìš©í•´ í´ëŸ¬ìŠ¤í„°, ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜, êµ¬ì¡°ì  API ë¥¼ ì‚´í´ë³´ê³ <br>ìŠ¤íŒŒí¬ì˜ í•µì‹¬ìš©ì–´ì™€ ê°œë…, ì‚¬ìš©ë²•ì„ ìµíŒë‹¤.</p>
<h3 id="2-1-ìŠ¤íŒŒí¬ì˜-ê¸°ë³¸-ì•„í‚¤í…ì²˜"><a href="#2-1-ìŠ¤íŒŒí¬ì˜-ê¸°ë³¸-ì•„í‚¤í…ì²˜" class="headerlink" title="2.1 ìŠ¤íŒŒí¬ì˜ ê¸°ë³¸ ì•„í‚¤í…ì²˜"></a>2.1 ìŠ¤íŒŒí¬ì˜ ê¸°ë³¸ ì•„í‚¤í…ì²˜</h3><blockquote>
<p>ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì´í•´í•˜ê¸° ìœ„í•œ í•µì‹¬ì‚¬í•­</p>
<ul>
<li>ìŠ¤íŒŒí¬ëŠ” ì‚¬ìš©ê°€ëŠ¥í•œ ìì›ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ <strong>í´ëŸ¬ìŠ¤í„° ë§¤ë‹ˆì €</strong> ì‚¬ìš©</li>
<li><strong>ë“œë¼ì´ë²„</strong> í”„ë¡œì„¸ìŠ¤ëŠ” ì£¼ì–´ì§ ì‘ì—…ì„ ì™„ë£Œí•˜ê¸°ìœ„í•´, ë“œë¼ì´ë²„ í”„ë¡œê·¸ë¨ì˜ ëª…ë ¹ì„ <strong>ìµìŠ¤íí„°</strong>ì—ì„œ ì‹¤í–‰í•  ì±…ì„ì´ ìˆìŒ</li>
</ul>
</blockquote>
<ul>
<li>ìŠ¤íŒŒí¬ëŠ” í´ëŸ¬ìŠ¤í„°ì˜ ë°ì´í„° ì²˜ë¦¬ ì‘ì—…ì„ ê´€ë¦¬ / ì¡°ìœ¨<ul>
<li>ì»´í“¨í„° í´ëŸ¬ìŠ¤í„°ëŠ” ì—¬ëŸ¬ ì»´í“¨í„°ì˜ ìì›ì„ ëª¨ì•„ í•˜ë‚˜ì˜ ì»´í“¨í„° ì²˜ëŸ¼ ì‚¬ìš©</li>
<li>í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‘ì—…ì„ ì¡°ìœ¨í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ =&gt; <strong>ìŠ¤íŒŒí¬</strong></li>
</ul>
</li>
<li>ìŠ¤íŒŒí¬ê°€ ì—°ì‚°ì— ì‚¬ìš©í•  í´ëŸ¬ìŠ¤í„°ë¥¼ ê´€ë¦¬í•˜ëŠ” <strong>í´ëŸ¬ìŠ¤í„° ë§¤ë‹ˆì €</strong><ul>
<li>ìŠ¤íŒŒí¬ standalone í´ëŸ¬ìŠ¤í„° ë§¤ë‹ˆì €, í•˜ë‘¡ YARN, Mesos</li>
<li>ì—­í• <ul>
<li>ì‚¬ìš©ì : ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ì œì¶œ (submit)</li>
<li>-&gt; í´ëŸ¬ìŠ¤í„° ë§¤ë‹ˆì € : ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ì— í•„ìš”í•œ ìì› í• ë‹¹ </li>
<li>-&gt; í• ë‹¹ë°›ì€ ìì›ìœ¼ë¡œ ì‘ì—… ì²˜ë¦¬</li>
</ul>
</li>
</ul>
</li>
<li>ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ = <code>driver</code> í”„ë¡œì„¸ìŠ¤ + ë‹¤ìˆ˜ì˜ <code>executor</code> í”„ë¡œì„¸ìŠ¤<ul>
<li><code>driver</code> í”„ë¡œì„¸ìŠ¤<ul>
<li>í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ì¤‘ í•˜ë‚˜ì—ì„œ ì‹¤í–‰. main() í•¨ìˆ˜ ì‹¤í–‰</li>
<li>ì‹¬ì¥ê³¼ ê°™ì€ ì¡´ì¬ë¡œ, ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª… ì£¼ê¸° ë™ì•ˆ ê´€ë ¨ ì •ë³´ ëª¨ë‘ ìœ ì§€</li>
</ul>
</li>
<li><code>executor</code> í”„ë¡œì„¸ìŠ¤<ul>
<li>driver ê°€ í• ë‹¹í•œ ì‘ì—… ìˆ˜í–‰ &amp; ì§„í–‰ ìƒí™©ì„ driverì—ê²Œ ë³´ê³ </li>
<li>ëŒ€ë¶€ë¶„ ìŠ¤íŒŒí¬ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ì—­í• ë¡œ, ìŠ¤íŒŒí¬ ì–¸ì–´ APIë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì–¸ì–´ë¡œ ì‹¤í–‰ ê°€ëŠ¥</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2-2-ìŠ¤íŒŒí¬ì˜-ë‹¤ì–‘í•œ-ì–¸ì–´-API"><a href="#2-2-ìŠ¤íŒŒí¬ì˜-ë‹¤ì–‘í•œ-ì–¸ì–´-API" class="headerlink" title="2.2 ìŠ¤íŒŒí¬ì˜ ë‹¤ì–‘í•œ ì–¸ì–´ API"></a>2.2 ìŠ¤íŒŒí¬ì˜ ë‹¤ì–‘í•œ ì–¸ì–´ API</h3><ul>
<li>ìŠ¤íŒŒí¬ëŠ” ëª¨ë“  ì–¸ì–´ì— ë§ëŠ” ëª‡ëª‡ â€˜í•µì‹¬ ê°œë…â€™ ì œê³µ<ul>
<li>í•µì‹¬ê°œë… -&gt; (í´ëŸ¬ìŠ¤í„° ë¨¸ì‹ ì—ì„œ ì‹¤í–‰ë˜ëŠ”) ìŠ¤íŒŒí¬ ì½”ë“œ ë¡œ ë³€í™˜</li>
<li>êµ¬ì¡°ì  APIë§Œìœ¼ë¡œ ì‘ì„±ëœ ì½”ë“œëŠ” ì–¸ì–´ì— ë¬´ê´€í•˜ê²Œ ìœ ì‚¬ ì„±ëŠ¥</li>
</ul>
</li>
<li>ì–¸ì–´ë³„ ìš”ì•½ ì •ë³´<ul>
<li>Scala : ìŠ¤íŒŒí¬ê°€ ìŠ¤ì¹¼ë¼ ê¸°ë°˜. <strong>ìŠ¤íŒŒí¬ì˜ ê¸°ë³¸ ì–¸ì–´</strong></li>
<li>Java : <del>ìë°” ì§€ì›ì•ˆí•´ì£¼ë©´ ë‚œë¦¬ì¹ ê±°ë‹ˆê¹Œ</del> ì§€ì›ì€ í•¨</li>
<li>Python : ìŠ¤ì¹¼ë¼ê°€ ì§€ì›í•˜ëŠ” ê±°ì˜ ëª¨ë“  êµ¬ì¡° ì§€ì›</li>
<li>SQL : ANSI SQL:2003 í‘œì¤€ ì¤‘ ì¼ë¶€ ì§€ì›</li>
<li>R : ìŠ¤íŒŒí¬ ì½”ì–´ì˜ sparkR, R ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ì˜ sparklyr</li>
</ul>
</li>
<li>SparkSession ê°ì²´<ul>
<li>ì‚¬ìš©ìê°€ ìŠ¤íŒŒí¬ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê¸°ìœ„í•´ ì§„ì…ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥</li>
<li>Python, R ì‚¬ìš© ì‹œì—ë„ ì‚¬ìš©ì ëŒ€ì‹  ìµìŠ¤íí„°ì˜ JVMì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì½”ë“œë¡œ ë³€í™˜</li>
</ul>
</li>
</ul>
<h3 id="2-3-ìŠ¤íŒŒí¬-API"><a href="#2-3-ìŠ¤íŒŒí¬-API" class="headerlink" title="2.3 ìŠ¤íŒŒí¬ API"></a>2.3 ìŠ¤íŒŒí¬ API</h3><ul>
<li>ë‹¤ì–‘í•œ ì–¸ì–´ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì´ìœ ?<ul>
<li>ìŠ¤íŒŒí¬ê°€ ê¸°ë³¸ì ìœ¼ë¡œ ì œê³µí•˜ëŠ” 2ê°€ì§€ API ë•Œë¬¸<ul>
<li>ì €ìˆ˜ì¤€ì˜ ë¹„êµ¬ì¡°ì (unstructured) API</li>
<li>ê³ ìˆ˜ì¤€ì˜ êµ¬ì¡°ì (structured) API</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2-4-ìŠ¤íŒŒí¬-ì‹œì‘í•˜ê¸°"><a href="#2-4-ìŠ¤íŒŒí¬-ì‹œì‘í•˜ê¸°" class="headerlink" title="2.4 ìŠ¤íŒŒí¬ ì‹œì‘í•˜ê¸°"></a>2.4 ìŠ¤íŒŒí¬ ì‹œì‘í•˜ê¸°</h3><ul>
<li>Q. ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ë ¤ë©´<ul>
<li>A. ì‚¬ìš©ì ëª…ë ¹ê³¼ ë°ì´í„°ë¥¼ ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì „ì†¡í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ì•¼</li>
</ul>
</li>
<li>SparkSession ìƒì„± ì‹¤ìŠµ. ì ë“œê°€ì~</li>
</ul>
<h3 id="2-5-SparkSession"><a href="#2-5-SparkSession" class="headerlink" title="2.5 SparkSession"></a>2.5 SparkSession</h3><ul>
<li><strong>SparkSession</strong> : ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì œì–´í•˜ëŠ” ë“œë¼ì´ë²„ í”„ë¡œì„¸ìŠ¤<ul>
<li>ì‚¬ìš©ìê°€ ì •ì˜í•œ ì²˜ë¦¬ëª…ë ¹ -&gt; í´ëŸ¬ìŠ¤í„°ì— ì‹¤í–‰</li>
<li>ìŠ¤íŒŒí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì— 1:1 ëŒ€ì‘</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> scala console</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ./spark-2.4.7-bin-hadoop2.7/bin/spark-shell</span></span><br><span class="line"></span><br><span class="line"><span class="meta">scala&gt;</span><span class="bash"> spark</span></span><br><span class="line">res0: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@5b58f639</span><br><span class="line"><span class="meta">scala&gt;</span><span class="bash"> val myRange = spark.range(1000).toDF(<span class="string">&quot;number&quot;</span>)</span></span><br><span class="line">myRange: org.apache.spark.sql.DataFrame = [number: bigint]</span><br></pre></td></tr></table></figure>
<h3 id="2-6-DataFrame"><a href="#2-6-DataFrame" class="headerlink" title="2.6 DataFrame"></a>2.6 DataFrame</h3><ul>
<li><strong>DataFrame</strong> : ê°€ì¥ ëŒ€í‘œì ì¸ <strong>êµ¬ì¡°ì  API</strong><ul>
<li>í…Œì´ë¸” ë°ì´í„°ë¥¼ row, column ìœ¼ë¡œ ë‹¨ìˆœí•˜ê²Œ í‘œí˜„<ul>
<li>scheme : column ê³¼ column type ì„ ì •ì˜í•œ ëª©ë¡</li>
</ul>
</li>
<li>DataFrame ì€ ìˆ˜ì²œ ëŒ€ì˜ ì»´í“¨í„°ì— ë¶„ì‚° ê°€ëŠ¥</li>
<li>vs ìŠ¤í”„ë ˆë“œ ì‹œíŠ¸<ul>
<li>ë¹„ìŠ·í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆì§€ë§Œ ìŠ¤í”„ë ˆë“œ ì‹œíŠ¸ëŠ” ë‹¨ì¼ ì»´í“¨í„° ì €ì¥</li>
</ul>
</li>
<li>vs Python (Pandas)ì˜ DataFrame, Rì˜ DataFrame<ul>
<li>ë§ˆì°¬ê°€ì§€ë¡œ ëŒ€ë¶€ë¶„ ë‹¨ì¼ ì»´í“¨í„°ì— ì¡´ì¬</li>
<li>=&gt; ìŠ¤íŒŒí¬ DataFrameìœ¼ë¡œ ì‰½ê²Œ ë³€í™˜ ê°€ëŠ¥</li>
</ul>
</li>
</ul>
</li>
<li>ìŠ¤íŒŒí¬ì˜ í•µì‹¬ ì¶”ìƒí™” ê°œë… (ë¶„ì‚° ë°ì´í„° ëª¨ìŒ)<ul>
<li>Dataset, DataFrame, SQL í…Œì´ë¸”, RDD</li>
</ul>
</li>
<li>DataFrameì˜ íŒŒí‹°ì…˜<ul>
<li>ìµìŠ¤íí„°ê°€ ë³‘ë ¬ë¡œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ë°ì´í„°ë¥¼ ë¶„í• í•˜ëŠ” ì²­í¬ ë‹¨ìœ„</li>
<li>ì‹¤í–‰ ì¤‘ ë°ì´í„°ê°€ í´ëŸ¬ìŠ¤í„°ì—ì„œ ë¬¼ë¦¬ì ìœ¼ë¡œ ë¶„ì‚°ë˜ëŠ” ë°©ì‹ì„ ë‚˜íƒ€ëƒ„<ul>
<li>íŒŒí‹°ì…˜ 1 ìµìŠ¤íí„° 1000 =&gt; ë³‘ë ¬ì„± 1</li>
<li>íŒŒí‹°ì…˜ 1000 ìµìŠ¤íí„° 1 =&gt; ë³‘ë ¬ì„± 1</li>
</ul>
</li>
<li>ë¬¼ë¦¬ì  íŒŒí‹°ì…˜ì— ë°ì´í„° ë³€í™˜ìš© í•¨ìˆ˜ ì§€ì • ì‹œ ìŠ¤íŒŒí¬ê°€ ì‹¤ì œ ì²˜ë¦¬ ë°©ë²• ê²°ì • (íŒŒí‹°ì…˜ ìˆ˜ë™ ì²˜ë¦¬ í•„ìš” X)</li>
</ul>
</li>
</ul>
<h3 id="2-7-íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜"><a href="#2-7-íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜" class="headerlink" title="2.7 íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜"></a>2.7 íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜</h3><ul>
<li>ìŠ¤íŒŒí¬ì˜ í•µì‹¬ ë°ì´í„° êµ¬ì¡° =&gt; <strong>ë¶ˆë³€ì„± (immutable)</strong><ul>
<li>DataFrameì„ ë³€ê²½í•˜ë ¤ë©´?</li>
<li>ì›í•˜ëŠ” ë³€ê²½ ë°©ë²•ì„ ìŠ¤íŒŒí¬ì—ê²Œ ì•Œë ¤ì¤˜ì•¼í•¨ =&gt; <strong>íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜</strong></li>
</ul>
</li>
<li>íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ : ìŠ¤íŒŒí¬ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ í‘œí˜„í•˜ëŠ” í•µì‹¬ ê°œë…<ul>
<li>ìœ í˜•<ul>
<li>ì¢ì€ ì˜ì¡´ì„± (narrow dependency)<ul>
<li>ì…ë ¥ íŒŒí‹°ì…˜ : ì¶œë ¥ íŒŒí‹°ì…˜ = 1 : 1</li>
</ul>
</li>
<li>ë„“ì€ ì˜ì¡´ì„± (wide dependency)<ul>
<li>ì…ë ¥ íŒŒí‹°ì…˜ : ì¶œë ¥ íŒŒí‹°ì…˜ = 1 : N</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>ì§€ì—° ì—°ì‚° (lazy evaluation) : ì—°ì‚° ê·¸ë˜í”„ë¥¼ ì²˜ë¦¬í•˜ê¸° ì§ì „ê¹Œì§€ ê¸°ë‹¤ë¦¬ëŠ” ë™ì‘ ë°©ì‹<ul>
<li>ìŠ¤íŒŒí¬ëŠ” ì—°ì‚° ëª…ë ¹ ì¦‰ì‹œ ë°ì´í„°ë¥¼ ìˆ˜ì • X. ì›ì‹œ ë°ì´í„°ì— ì ìš©í•  íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ì˜ <strong>ì‹¤í–‰ ê³„íš</strong>ì„ ìƒì„±</li>
<li>ë§ˆì§€ë§‰ê¹Œì§€ ëŒ€ê¸°í•˜ë‹¤ DataFrame íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ì„ ê°„ê²°í•œ ë¬¼ë¦¬ì  ì‹¤í–‰ ê³„íšìœ¼ë¡œ ì»´íŒŒì¼ =&gt; ì „ì²´ ë°ì´í„° íë¦„ ìµœì í™”</li>
<li>ex. DataFrame ì˜ predicate pushdown</li>
</ul>
</li>
</ul>
<h3 id="2-8-ì•¡ì…˜"><a href="#2-8-ì•¡ì…˜" class="headerlink" title="2.8 ì•¡ì…˜"></a>2.8 ì•¡ì…˜</h3><ul>
<li>íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ì€ ë…¼ë¦¬ì  ì‹¤í–‰ ê³„íš<ul>
<li>íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ì„ ì„ ì–¸í•´ë„ ì•¡ì…˜ì„ í˜¸ì¶œí•˜ì§€ ì•Šìœ¼ë©´ ìˆ˜í–‰ X</li>
</ul>
</li>
<li>ì•¡ì…˜ (action) : ì‹¤ì œ ì—°ì‚°ì„ ìˆ˜í–‰<ul>
<li>ìœ í˜•<ul>
<li>ì½˜ì†”ì—ì„œ ë°ì´í„°ë¥¼ ë³´ëŠ” ì•¡ì…˜</li>
<li>ê° ì–¸ì–´ë¡œ ëœ ë„¤ì´í‹°ë¸Œ ê°ì²´ì— ë°ì´í„°ë¥¼ ëª¨ìœ¼ëŠ” ì•¡ì…˜</li>
<li>ì¶œë ¥ ë°ì´í„°ì†ŒìŠ¤ì— ì €ì¥í•˜ëŠ” ì•¡ì…˜</li>
</ul>
</li>
</ul>
</li>
<li>ì•¡ì…˜ ì§€ì • ì‹œ ìŠ¤íŒŒí¬ ì¡ ì‹œì‘<ul>
<li><strong>ìŠ¤íŒŒí¬ ì¡ (job)</strong><ul>
<li>í•„í„° (ì¢ì€ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜) ìˆ˜í–‰</li>
<li>-&gt; íŒŒí‹°ì…˜ ë³„ë¡œ ë ˆì½”ë“œ ìˆ˜ë¥¼ ì¹´ìš´íŠ¸ (ë„“ì€ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜)</li>
<li>-&gt; ê° ì–¸ì–´ì— ì í•©í•œ ë„¤ì´í‹°ë¸Œ ê°ì²´ì— ê²°ê³¼ ëª¨ìŒ</li>
</ul>
</li>
<li>ìŠ¤íŒŒí¬ UIë¡œ ì¡ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥</li>
<li><em>ìŠ¤íŒŒí¬ ì¡ì€ ê°œë³„ ì•¡ì…˜ì— ì˜í•´ íŠ¸ë¦¬ê±°ë˜ëŠ” ë‹¤ìˆ˜ì˜ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤</em></li>
</ul>
</li>
</ul>
<h3 id="2-9-ìŠ¤íŒŒí¬-UI"><a href="#2-9-ìŠ¤íŒŒí¬-UI" class="headerlink" title="2.9 ìŠ¤íŒŒí¬ UI"></a>2.9 ìŠ¤íŒŒí¬ UI</h3><ul>
<li>ë“œë¼ì´ë²„ ë…¸ë“œì˜ 4040 í¬íŠ¸</li>
<li>ìŠ¤íŒŒí¬ ì¡ì˜ ìƒíƒœ, í™˜ê²½ ì„¤ì •, í´ëŸ¬ìŠ¤í„° ìƒíƒœ ë“±ì˜ ì •ë³´ í™•ì¸ ê°€ëŠ¥</li>
</ul>
<h3 id="2-10-ì¢…í•©-ì˜ˆì œ"><a href="#2-10-ì¢…í•©-ì˜ˆì œ" class="headerlink" title="2.10 ì¢…í•© ì˜ˆì œ"></a>2.10 ì¢…í•© ì˜ˆì œ</h3><ul>
<li>ë¯¸êµ­ êµí†µí†µê³„êµ­ì˜ í•­ê³µìš´í•­ ë°ì´í„° ì¤‘ ì¼ë¶€ë¡œ ì‹¤ìŠµ<ul>
<li><a target="_blank" rel="noopener" href="https://bit.ly/2yw2fCx">ìƒ˜í”Œ ë°ì´í„°</a> : ë°˜ì •í˜•(semi-structured), csv í¬ë§·</li>
<li>(=&gt; ë¶€ë¡ Aì˜ ë„ì»¤ ì´ë¯¸ì§€ ì‚¬ìš© ì‹œ ì´ë¯¸ í¬í•¨)</li>
</ul>
</li>
<li>ìŠ¤íŒŒí¬ëŠ” ë‹¤ì–‘í•œ ë°ì´í„°ì†ŒìŠ¤ ì§€ì›<ul>
<li>SparkSessionì˜ DataFrameReader í´ë˜ìŠ¤ ì‚¬ìš©í•´ì„œ ì½ìŒ</li>
<li>ì˜ˆì œëŠ” <strong>ìŠ¤í‚¤ë§ˆ ì¶”ë¡  (Schema inference)</strong> ê¸°ëŠ¥ ì¶”ê°€<ul>
<li>ìŠ¤íŒŒí¬ëŠ” ê° ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì… ì¶”ë¡ ì„ ìœ„í•´ ì ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ ì½ìŒ </li>
</ul>
</li>
<li>DataFrame ì€ ë¶ˆíŠ¹ì  ë‹¤ìˆ˜ì˜ ë¡œìš°ì™€ ì»¬ëŸ¼<ul>
<li>ì§€ì—° ì—°ì‚° í˜•íƒœì˜ íŠ¸ë ŒìŠ¤í¬ë©”ì´ì…˜ì´ë¯€ë¡œ row ìˆ˜ ì•Œ ìˆ˜ X</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="ì˜ˆì œ-1"><a href="#ì˜ˆì œ-1" class="headerlink" title="ì˜ˆì œ 1"></a>ì˜ˆì œ 1</h4><details><summary class="point-color-can-hover">ì˜ˆì œ 1 í¼ì¹˜ê¸°</summary>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ head /data/flight-data/csv/2015-summary.csv</span><br><span class="line">DEST_COUNTRY_NAME,ORIGIN_COUNTRY_NAME,count</span><br><span class="line">United States,Romania,15</span><br><span class="line">United States,Croatia,1</span><br><span class="line">..</span><br><span class="line"></span><br><span class="line"><span class="comment"># spark-shell (scala)</span></span><br><span class="line">scala&gt; val flightData2015 = spark.read.option(<span class="string">&quot;inferSchema&quot;</span>, <span class="string">&quot;true&quot;</span>).option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>).csv(<span class="string">&quot;/data/flight-data/csv/2015-summary.csv&quot;</span>)</span><br><span class="line">flightData2015: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]</span><br><span class="line"></span><br><span class="line">scala&gt; flightData2015.take(3)</span><br><span class="line">res0: Array[org.apache.spark.sql.Row] = Array([United States,Romania,15], [United States,Croatia,1], [United States,Ireland,344])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scala&gt; flightData2015.sort(<span class="string">&quot;count&quot;</span>).explain()</span><br><span class="line">== Physical Plan ==</span><br><span class="line">*(2) Sort [count<span class="comment">#12 ASC NULLS FIRST], true, 0</span></span><br><span class="line">+- Exchange rangepartitioning(count<span class="comment">#12 ASC NULLS FIRST, 200)</span></span><br><span class="line">   +- *(1) FileScan csv [DEST_COUNTRY_NAME<span class="comment">#10,ORIGIN_COUNTRY_NAME#11,count#12] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/data/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ì…”í”Œ íŒŒí‹°ì…˜ default 200ê°œ =&gt; 5ê°œ</span></span><br><span class="line">scala&gt; spark.conf.set(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="string">&quot;5&quot;</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; flightData2015.sort(<span class="string">&quot;count&quot;</span>).explain()</span><br><span class="line">== Physical Plan ==</span><br><span class="line">*(2) Sort [count<span class="comment">#12 ASC NULLS FIRST], true, 0</span></span><br><span class="line">+- Exchange rangepartitioning(count<span class="comment">#12 ASC NULLS FIRST, 5)</span></span><br><span class="line">   +- *(1) FileScan csv [DEST_COUNTRY_NAME<span class="comment">#10,ORIGIN_COUNTRY_NAME#11,count#12] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/data/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int&gt;</span></span><br><span class="line"></span><br><span class="line">scala&gt; flightData2015.sort(<span class="string">&quot;count&quot;</span>).take(2)</span><br><span class="line">res3: Array[org.apache.spark.sql.Row] = Array([United States,Singapore,1], [Moldova,United States,1])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>

<blockquote>
<ul>
<li><code>take(n)</code> : Action</li>
<li><code>sort()</code> :  Transformation (ë„“ì€) <ul>
<li>DataFrame ì„ ë³€ê²½í•˜ì§€ ì•Šê³  ìƒˆë¡œìš´ DataFrameì„ ìƒì„±í•´ ë°˜í™˜</li>
</ul>
</li>
<li><code>explain()</code> <ul>
<li>DataFrameì˜ ê³„ë³´(lineage) ë‚˜ ìŠ¤íŒŒí¬ ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ì¶œë ¥</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li>ì‹¤í–‰ ê³„íš? : ë””ë²„ê¹…ê³¼ ìŠ¤íŒŒí¬ì˜ ì‹¤í–‰ê³¼ì •ì„ ì´í•´í•˜ëŠ”ë° ë„ì›€ì„ ì£¼ëŠ” ë„êµ¬<ul>
<li>ìœ„ì—ì„œ ì•„ë˜ë°©í–¥ìœ¼ë¡œ ì½ëŠ”ë‹¤</li>
<li>ìµœì¢… ê²°ê³¼ëŠ” ê°€ì¥ ìœ„, ë°ì´í„°ì†ŒìŠ¤ëŠ” ê°€ì¥ ì•„ë˜</li>
</ul>
</li>
<li>DataFrameì˜ ê³„ë³´<ul>
<li>íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ì˜ ë…¼ë¦¬ì  ì‹¤í–‰ ê³„íš -&gt; DataFrameì˜ ê³„ë³´ ì •ì˜</li>
<li>-&gt; ê³„ë³´ë¥¼ í†µí•´ ìŠ¤íŒŒí¬ê°€ ì…ë ¥ë°ì´í„°ì— ìˆ˜í–‰í•œ ì—°ì‚°ì„ ì „ì²´ íŒŒí‹°ì…˜ì—ì„œ ì–´ë–»ê²Œ ì¬ì—°ì‚°í•˜ëŠ”ì§€ ì•Œ ìˆ˜ ìˆìŒ</li>
<li><em>í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°ì˜ í•µì‹¬</em> (Pure Function, ê°™ì€ ì…ë ¥ -&gt; ê°™ì€ ì¶œë ¥)</li>
</ul>
</li>
<li>ì‚¬ìš©ìëŠ” ë¬¼ë¦¬ì  ë°ì´í„°ë¥¼ ì§ì ‘ ë‹¤ë£¨ì§€ ì•Šê³ , ë¬¼ë¦¬ì  ì‹¤í–‰ íŠ¹ì„±ì„ ì œì–´<ul>
<li>ì˜ˆì‹œ =&gt; íŒŒí‹°ì…˜ ìˆ˜ ë³€ê²½ <code>spark.conf.set(&quot;spark.sql.shuffle.partitions&quot;, &quot;5&quot;)</code></li>
<li>ìŠ¤íŒŒí¬ UI (4040 í¬íŠ¸) ì—ì„œ ìŠ¤íŒŒí¬ ì¡ ë¬¼ë¦¬ì , ë…¼ë¦¬ì  ì‹¤í–‰ íŠ¹ì„± í™•ì¸ ê°€ëŠ¥ <img width="500" alt="sparkui" src="https://user-images.githubusercontent.com/26691216/105624926-cfbfdf00-5e68-11eb-9407-e58a5f4688a9.png">


</li>
</ul>
</li>
</ul>
<h4 id="ì˜ˆì œ-2-SQL"><a href="#ì˜ˆì œ-2-SQL" class="headerlink" title="ì˜ˆì œ 2 (SQL)"></a>ì˜ˆì œ 2 (SQL)</h4><details><summary class="point-color-can-hover">ì˜ˆì œ 2-1 í¼ì¹˜ê¸°</summary>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1) SQL ì‚¬ìš©</span></span><br><span class="line">scala&gt; flightData2015.createOrReplaceTempView(<span class="string">&quot;flight_data_2015&quot;</span>)</span><br><span class="line">scala&gt; val sqlWay = spark.sql(<span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">     | SELECT DEST_COUNTRY_NAME, count(1)</span></span><br><span class="line"><span class="string">     | FROM flight_data_2015</span></span><br><span class="line"><span class="string">     | GROUP BY DEST_COUNTRY_NAME</span></span><br><span class="line"><span class="string">     | &quot;</span><span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; sqlWay.explain</span><br><span class="line">== Physical Plan ==</span><br><span class="line">*(2) HashAggregate(keys=[DEST_COUNTRY_NAME<span class="comment">#10], functions=[count(1)])</span></span><br><span class="line">+- Exchange hashpartitioning(DEST_COUNTRY_NAME<span class="comment">#10, 5)</span></span><br><span class="line">   +- *(1) HashAggregate(keys=[DEST_COUNTRY_NAME<span class="comment">#10], functions=[partial_count(1)])</span></span><br><span class="line">      +- *(1) FileScan csv [DEST_COUNTRY_NAME<span class="comment">#10] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/data/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;DEST_COUNTRY_NAME:string&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2) DataFrame ì‚¬ìš©</span></span><br><span class="line">scala&gt; val dataFrameWay = flightData2015.groupBy(<span class="string">&quot;DEST_COUNTRY_NAME&quot;</span>).count()</span><br><span class="line">dataFrameWay: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, count: bigint]</span><br><span class="line"></span><br><span class="line">scala&gt; dataFrameWay.explain</span><br><span class="line">== Physical Plan ==</span><br><span class="line">*(2) HashAggregate(keys=[DEST_COUNTRY_NAME<span class="comment">#10], functions=[count(1)])</span></span><br><span class="line">+- Exchange hashpartitioning(DEST_COUNTRY_NAME<span class="comment">#10, 5)</span></span><br><span class="line">   +- *(1) HashAggregate(keys=[DEST_COUNTRY_NAME<span class="comment">#10], functions=[partial_count(1)])</span></span><br><span class="line">      +- *(1) FileScan csv [DEST_COUNTRY_NAME<span class="comment">#10] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/data/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;DEST_COUNTRY_NAME:string&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>

<ul>
<li>ìŠ¤íŒŒí¬ëŠ” ì–¸ì–´ì— ë¬´ê´€í•˜ê²Œ ê°™ì€ ë°©ì‹ìœ¼ë¡œ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì‹¤í–‰<ul>
<li>SQL, DataFrame(R, Python, Scalar, Java) ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ í‘œí˜„</li>
<li>ìŠ¤íŒŒí¬ì—ì„œ ì½”ë“œ ì‹¤í–‰ ì „ì— ë¡œì§ì„ ê¸°ë³¸ ì‹¤í–‰ê³„íš(<code>explain</code>) ìœ¼ë¡œ ì»´íŒŒì¼</li>
</ul>
</li>
<li>ìŠ¤íŒŒí¬ SQL ì‚¬ìš©ì‹œ ëª¨ë“  DataFrame =&gt; í…Œì´ë¸”, ë·° (ì„ì‹œ í…Œì´ë¸”) ë¡œ ë“±ë¡<ul>
<li>ìœ„ì—ì„œ ì„¤ëª…í–ˆë“¯ <strong>ê°™ì€ ì‹¤í–‰ ê³„íš</strong>ìœ¼ë¡œ ì»´íŒŒì¼í•˜ë¯€ë¡œ ì„±ëŠ¥ì°¨ì´ X</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">ì˜ˆì œ 2-2 í¼ì¹˜ê¸°</summary>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &#x27;ìµœëŒ€ ë¹„í–‰ íšŸìˆ˜&#x27; êµ¬í•˜ê¸°</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SQL ì¿¼ë¦¬</span></span><br><span class="line">scala&gt; spark.sql(<span class="string">&quot;SELECT max(count) from flight_data_2015&quot;</span>).take(1)</span><br><span class="line">res9: Array[org.apache.spark.sql.Row] = Array([370002])</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataFrame êµ¬ë¬¸ _ max í•¨ìˆ˜ (íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜) ì‚¬ìš©</span></span><br><span class="line">scala&gt; import org.apache.spark.sql.functions.max</span><br><span class="line"></span><br><span class="line">scala&gt; flightData2015.select(max(<span class="string">&quot;count&quot;</span>)).take(1)</span><br><span class="line">res10: Array[org.apache.spark.sql.Row] = Array([370002])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &#x27;ìƒìœ„ 5ê°œì˜ ë„ì°© êµ­ê°€&#x27; êµ¬í•˜ê¸°</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SQL ì¿¼ë¦¬</span></span><br><span class="line">scala&gt; val maxSql = spark.sql(<span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">     | SELECT DEST_COUNTRY_NAME, sum(count) as destination_total</span></span><br><span class="line"><span class="string">     | FROM flight_data_2015</span></span><br><span class="line"><span class="string">     | GROUP BY DEST_COUNTRY_NAME</span></span><br><span class="line"><span class="string">     | ORDER BY sum(count) DESC</span></span><br><span class="line"><span class="string">     | LIMIT 5</span></span><br><span class="line"><span class="string">     | &quot;</span><span class="string">&quot;&quot;</span>)</span><br><span class="line">maxSql: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, destination_total: bigint]</span><br><span class="line"></span><br><span class="line">scala&gt; maxSql.show()</span><br><span class="line">+-----------------+-----------------+</span><br><span class="line">|DEST_COUNTRY_NAME|destination_total|</span><br><span class="line">+-----------------+-----------------+</span><br><span class="line">|    United States|           411352|</span><br><span class="line">|           Canada|             8399|</span><br><span class="line">|           Mexico|             7140|</span><br><span class="line">|   United Kingdom|             2025|</span><br><span class="line">|            Japan|             1548|</span><br><span class="line">+-----------------+-----------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># DataFrame êµ¬ë¬¸</span></span><br><span class="line">scala&gt; import org.apache.spark.sql.functions.desc</span><br><span class="line"></span><br><span class="line">scala&gt; flightData2015.groupBy(<span class="string">&quot;DEST_COUNTRY_NAME&quot;</span>).sum(<span class="string">&quot;count&quot;</span>).withColumnRenamed(<span class="string">&quot;sum(count)&quot;</span>, <span class="string">&quot;destination_total&quot;</span>).sort(desc(<span class="string">&quot;destination_total&quot;</span>)).<span class="built_in">limit</span>(5).show()</span><br><span class="line">+-----------------+-----------------+</span><br><span class="line">|DEST_COUNTRY_NAME|destination_total|</span><br><span class="line">+-----------------+-----------------+</span><br><span class="line">|    United States|           411352|</span><br><span class="line">|           Canada|             8399|</span><br><span class="line">|           Mexico|             7140|</span><br><span class="line">|   United Kingdom|             2025|</span><br><span class="line">|            Japan|             1548|</span><br><span class="line">+-----------------+-----------------+</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì½”ë“œ ìˆ˜í–‰ ë‹¨ê³„ : CSV íŒŒì¼ =&gt; (1) read -&gt; (2) groupBy -&gt; (3) sum -&gt; (4) withColumnRenamed -&gt; (5) sort -&gt; (6) limit -&gt; (7) collect =&gt; Array(..)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># scala&gt; ~.explain</span></span><br><span class="line">== Physical Plan ==</span><br><span class="line">TakeOrderedAndProject(<span class="built_in">limit</span>=5, orderBy=[destination_total<span class="comment">#108L DESC NULLS LAST], output=[DEST_COUNTRY_NAME#10,destination_total#108L])</span></span><br><span class="line">+- *(2) HashAggregate(keys=[DEST_COUNTRY_NAME<span class="comment">#10], functions=[sum(cast(count#12 as bigint))])</span></span><br><span class="line">   +- Exchange hashpartitioning(DEST_COUNTRY_NAME<span class="comment">#10, 5)</span></span><br><span class="line">      +- *(1) HashAggregate(keys=[DEST_COUNTRY_NAME<span class="comment">#10], functions=[partial_sum(cast(count#12 as bigint))])</span></span><br><span class="line">         +- *(1) FileScan csv [DEST_COUNTRY_NAME<span class="comment">#10,count#12] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/data/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;DEST_COUNTRY_NAME:string,count:int&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>

<ul>
<li>ì‹¤í–‰ê³„íšì€ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ì˜ <strong>ì§€í–¥ì„± ë¹„ìˆœí™˜ ê·¸ë˜í”„ (Directed Acyclic Graph, DAG)</strong><ul>
<li>ì•¡ì…˜ì´ í˜¸ì¶œë˜ë©´ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤</li>
<li>DAGì˜ ê° ë‹¨ê³„ëŠ” ë¶ˆë³€ì„±ì„ ê°€ì§„ ì‹ ê·œ DataFrameì„ ìƒì„±</li>
</ul>
</li>
<li>ì˜ˆì œì˜ ì „ì²´ ì½”ë“œ ìˆ˜í–‰ ë‹¨ê³„ (7ë‹¨ê³„) ëŠ” p.86 [ê·¸ë¦¼ 2-10] ì°¸ì¡°<ul>
<li>ì‹¤ì œ ì‹¤í–‰ ê³„íš (<code>explain</code> ì´ ì¶œë ¥í•˜ëŠ”) ì€ ë¬¼ë¦¬ì ì¸ ì‹¤í–‰ ì‹œì ì—ì„œ ìˆ˜í–‰í•˜ëŠ” ìµœì í™”ë¡œ ì¸í•´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ</li>
<li>ì§ì ‘ explain í•´ë³´ë©´ ì±…ì˜ explain ê³¼ë„ ë‹¤ë¥´ê²Œ ì¶œë ¥ë¨ </li>
</ul>
</li>
</ul>
<h3 id="2-11-ì •ë¦¬"><a href="#2-11-ì •ë¦¬" class="headerlink" title="2.11 ì •ë¦¬"></a>2.11 ì •ë¦¬</h3><ul>
<li>íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜, ì•¡ì…˜, DataFrame ì‹¤í–‰ ê³„íš ìµœì í™” ë°©ë²•<ul>
<li>íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ì˜ ì§€í–¥ì„± ë¹„ìˆœí™˜ ê·¸ë˜í”„(DAG) ë¥¼ ì§€ì—° ì‹¤í–‰í•˜ì—¬ ìµœì í™”</li>
</ul>
</li>
<li>ì˜ˆì œë¥¼ í†µí•œ ë°ì´í„°ê°€ íŒŒí‹°ì…˜ìœ¼ë¡œ êµ¬ì„±ë˜ëŠ” ë°©ë²•, ë³µì¡í•œ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ ì‘ì—… ì‹¤í–‰ ë‹¨ê³„ í™•ì¸</li>
</ul>
<br/>

<h3 id="ğŸ“’-ë‹¨ì–´ì¥"><a href="#ğŸ“’-ë‹¨ì–´ì¥" class="headerlink" title="ğŸ“’ ë‹¨ì–´ì¥"></a>ğŸ“’ ë‹¨ì–´ì¥</h3><ul>
<li>ì…”í”Œ (Shuffle) : ìŠ¤íŒŒí¬ì¹´ í´ëŸ¬ìŠ¤í„°ì—ì„œ íŒŒí‹°ì…˜ì„ êµí™˜<ul>
<li>ìŠ¤íŒŒí¬ëŠ” ì…”í”Œì˜ ê²°ê³¼ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥</li>
</ul>
</li>
<li>ê°€í™˜ì„± (Commutative) : ë‘ ëŒ€ìƒì˜ ì—°ì‚° ê²°ê³¼ê°€ ìˆœì„œì™€ ê´€ê³„ì—†ì´ ë™ì¼ (-&gt; êµí™˜ ë²•ì¹™)</li>
</ul>
</div><p class="post-tags"><i class="fa fa-tags" aria-hidden="true"></i><a href="/tags/study/">#study</a><a href="/tags/book/">#book</a><a href="/tags/spark/">#spark</a><a href="/tags/apache/">#apache</a></p></article></div><footer><div class="paginator"><a class="prev" href="/2021/01/24/Spark-The-Definitive-Guide-3%EC%9E%A5/">PREV</a><a class="next" href="/2021/01/20/Spark-The-Definitive-Guide-1%EC%9E%A5/">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'minsw-github-io';
var disqus_identifier = '2021/01/24/Spark-The-Definitive-Guide-2ì¥/';
var disqus_title = '&amp;#039;Spark The Definitive Guide&amp;#039; 2ì¥ - ìŠ¤íŒŒí¬ ì°ì–´ë¨¹ê¸°';
var disqus_url = 'https://minsw.github.io/2021/01/24/Spark-The-Definitive-Guide-2ì¥/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//#{theme.disqus}.disqus.com/count.js" async></script><div class="copyright"><p>Â© 2018 - 2021 <a href="https://minsw.github.io">Lukka Min</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-143001954-1",'auto');ga('send','pageview');</script><link rel="stylesheet" href="//cdn.datatables.net/1.10.7/css/jquery.dataTables.min.css" media="screen" type="text/css"><script src="//cdn.datatables.net/1.10.7/js/jquery.dataTables.min.js"></script><script>$(function(){$('.datatable').dataTable( {"order": [[ 0, "desc" ]],"iDisplayLength": -1,"lengthMenu": [[10, 25, 50, -1], [10, 25, 50, "All"]]} );});</script></body></html>