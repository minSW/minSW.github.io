<!DOCTYPE html><html lang="ko"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> &#039;Spark The Definitive Guide&#039; 6장 - 데이터 타입 (비)공식 가이드북 · Look out</title><meta name="description" content="&amp;#039;Spark The Definitive Guide&amp;#039; 6장 - 데이터 타입 (비)공식 가이드북 - Lukka Min"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/cover.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"><link rel="search" type="application/opensearchdescription+xml" href="https://minsw.github.io/atom.xml" title="Look out"><script src="//code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/feed.xml" title="Look out" type="application/atom+xml">
</head><body><div class="wrap"><header><a class="logo-link" href="/"><img src="/cover.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a class="nav-list-link" href="/" target="_self">BLOG</a></li><li class="nav-list-item"><a class="nav-list-link" href="/archives/" target="_self">ARCHIVE</a></li><li class="nav-list-item"><a class="nav-list-link" href="/tags/" target="_self">TAG</a></li><li class="nav-list-item"><a class="nav-list-link" href="https://github.com/minSW" target="_blank">GITHUB</a></li></ul></header><main class="container"></main><div class="post"><article class="post-block"><h1 class="post-title">&#039;Spark The Definitive Guide&#039; 6장 - 데이터 타입 (비)공식 가이드북</h1><div class="post-info">2021년 2월 2일<span class="categories"><i class="fa fa-bookmark" aria-hidden="true"></i></span><a class="post-category" href="/categories/spark/">#spark</a></div><div class="post-content"><br/>

<center><p style="color:lightgray">라떼 시절엔,, 가이드북이 하나면 든-든했다,,, 이말이야,,, 총총 @}----</p>
<img width="300" alt="maple" src="https://user-images.githubusercontent.com/26691216/106801127-b149b700-66a4-11eb-9c8f-0802771ebe5f.jpg">
<i>'아파치 스파크' 미인증 비공식 가이드 북<br/>
[전원 증정] 50.00 페이지 포인트 (캐시 아이템 구매 가능)</i></center>


<br/>

<center><h2>_ _ _</h2></center>

<br/>

<hr>
<h1 id="CHAPTER-6-다양한-데이터-타입-다루기"><a href="#CHAPTER-6-다양한-데이터-타입-다루기" class="headerlink" title="CHAPTER 6 다양한 데이터 타입 다루기"></a>CHAPTER 6 다양한 데이터 타입 다루기</h1><p>CHAPTER 5 는 DataFrame의 기본 개념과 핵심 추상화 개념을 소개<br>CHAPTER 6 는 스파크의 구조적 연산에서 가장 중요한 내용인 <strong>표현식 만드는 방법</strong> 소개 + 다양한 데이터 타입 다루는 방법</p>
<blockquote>
<p>다양한 데이터 타입</p>
<ul>
<li>Boolean 타입</li>
<li>수치 타입</li>
<li>문자열 타입</li>
<li>date와 timestamp 타입</li>
<li>null 값 다루기</li>
<li>복합 데이터 아입</li>
<li>사용자 정의 함수</li>
</ul>
</blockquote>
<h3 id="6-1-API는-어디서-찾을까"><a href="#6-1-API는-어디서-찾을까" class="headerlink" title="6.1 API는 어디서 찾을까"></a>6.1 API는 어디서 찾을까</h3><ul>
<li>오늘은 언젠가 내일이 된다<ul>
<li>버전 바뀌면 책의 내용도 다 예전 내용이다~ 이말이야</li>
<li>=&gt; 따라서 <u>데이터 변환용 함수 찾는 방법</u> 을 알아야함</li>
</ul>
</li>
<li>어떻게 찾나?<ul>
<li>DataFrame (Dataset) 메서드<ul>
<li>DatasFrame은 Row타입을 가진 Dataset =&gt; <a target="_blank" rel="noopener" href="http://bit.ly/2rKkALY">Dataset API</a></li>
<li>다양한 메서드를 제공하는 Dataset 하위 모듈 (ex. <a target="_blank" rel="noopener" href="http://bit.ly/2DPYhJC">DataFrameStateFunctions</a> - 통계적 함수 제공, <a target="_blank" rel="noopener" href="http://bit.ly/2DPAqd3">DataFrameNaFunctions</a> - null 데이터 제어)</li>
</ul>
</li>
<li>Column 메서드<ul>
<li><code>alias</code> <code>contains</code> 등의 컬럼 관련 메서드 제공 =&gt; <a target="_blank" rel="noopener" href="http://bit.ly/2FloFbr">Columns API</a></li>
<li><code>org.apache.spark.sql.functions</code>는 데이터 타입 관련 다양한 함수 제공 (ex. <a target="_blank" rel="noopener" href="http://bit.ly/2DPAycx">SQL, DataFrame 함수 등</a>)</li>
</ul>
</li>
</ul>
</li>
<li>모든 함수는 데이터 로우의 특정 포맷이나 구조를 다른 형태로 변환하기 위해 존재<ul>
<li>함수로 더 많은 로우를 만들거나 줄일 수 O</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">[6.1] 예제 펼치기 - 분석용 DataFrame 생성 예제</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> df = (spark.read.format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;inferSchema&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">  .load(<span class="string">&quot;/data/retail-data/by-day/2010-12-01.csv&quot;</span>))</span><br><span class="line">df.printSchema()</span><br><span class="line">df.createOrReplaceTempView(<span class="string">&quot;dfTable&quot;</span>)</span><br><span class="line"><span class="comment">// df: org.apache.spark.sql.DataFrame = [InvoiceNo: string, StockCode: string ... 6 more fields]</span></span><br><span class="line"><span class="comment">// root</span></span><br><span class="line"><span class="comment">//  |-- InvoiceNo: string (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- StockCode: string (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Description: string (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Quantity: integer (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- InvoiceDate: timestamp (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- UnitPrice: double (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- CustomerID: double (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Country: string (nullable = true)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>


<h3 id="6-2-스파크-데이터-타입으로-변환하기"><a href="#6-2-스파크-데이터-타입으로-변환하기" class="headerlink" title="6.2 스파크 데이터 타입으로 변환하기"></a>6.2 스파크 데이터 타입으로 변환하기</h3><ul>
<li><code>lit()</code> : 데이터 타입 변환<ul>
<li>다른 프로그래밍 언어 고유 데이터 타입 =&gt; <strong>스파크 데이터 타입</strong> 변환</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">[6.2] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.lit</span><br><span class="line"></span><br><span class="line">df.select(lit(<span class="number">5</span>), lit(<span class="string">&quot;five&quot;</span>), lit(<span class="number">5.0</span>))</span><br><span class="line"><span class="comment">// res9: org.apache.spark.sql.DataFrame = [5: int, five: string ... 1 more field]</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- SQL (SQL은 스파크 데이터 타입 변환 필요 X. 직접 값 입력)</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">5</span>, &quot;five&quot;, <span class="number">5.0</span></span><br></pre></td></tr></table></figure>
</details>

<h3 id="6-3-불리언-데이터-타입-다루기"><a href="#6-3-불리언-데이터-타입-다루기" class="headerlink" title="6.3 불리언 데이터 타입 다루기"></a>6.3 불리언 데이터 타입 다루기</h3><ul>
<li><p>불리언은 모든 필터링 작업의 기반 (데이터 분석에 필수)</p>
</li>
<li><p>불리언 구문 : <code>and</code>, <code>or</code>, <code>true</code>, <code>false</code></p>
<ul>
<li>불리언 구문으로 논리 문법(true/false) 생성</li>
</ul>
</li>
<li><p><strong>스칼라</strong> 사용 시 동등 여부</p>
<ul>
<li><code>===</code> (일치) / <code>=!=</code> (불일치)</li>
<li><code>not()</code>, <code>equalTO()</code> 사용 가능</li>
</ul>
</li>
<li><p>파이썬, 스칼라 모두 사용할 수 있는</p>
<ul>
<li><p>가장 명확한 방법? =&gt; 문자열 표현식에 조건절 명시 (ex. <code>where(&quot;InvoiceNo = 536353)</code>)</p>
<details><summary class="point-color-can-hover">[6.3-1] 예제 펼치기 - 문자열 표현식에 조건절 명시 </summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.col</span><br><span class="line"></span><br><span class="line"><span class="comment">// 같은 표현식 (in Scala)</span></span><br><span class="line">(df.where(col(<span class="string">&quot;InvoiceNo&quot;</span>).equalTo(<span class="number">536365</span>))</span><br><span class="line">  .select(<span class="string">&quot;InvoiceNo&quot;</span>, <span class="string">&quot;Description&quot;</span>)</span><br><span class="line">  .show(<span class="number">5</span>, <span class="literal">false</span>))</span><br><span class="line">(df.where(col(<span class="string">&quot;InvoiceNo&quot;</span>) === <span class="number">536365</span>)</span><br><span class="line">  .select(<span class="string">&quot;InvoiceNo&quot;</span>, <span class="string">&quot;Description&quot;</span>)</span><br><span class="line">  .show(<span class="number">5</span>, <span class="literal">false</span>))</span><br><span class="line"><span class="comment">// +---------+-----------------------------------+</span></span><br><span class="line"><span class="comment">// |InvoiceNo|Description                        |</span></span><br><span class="line"><span class="comment">// +---------+-----------------------------------+</span></span><br><span class="line"><span class="comment">// |536365   |WHITE HANGING HEART T-LIGHT HOLDER |</span></span><br><span class="line"><span class="comment">// |536365   |WHITE METAL LANTERN                |</span></span><br><span class="line"><span class="comment">// |536365   |CREAM CUPID HEARTS COAT HANGER     |</span></span><br><span class="line"><span class="comment">// |536365   |KNITTED UNION FLAG HOT WATER BOTTLE|</span></span><br><span class="line"><span class="comment">// |536365   |RED WOOLLY HOTTIE WHITE HEART.     |</span></span><br><span class="line"><span class="comment">// +---------+-----------------------------------+</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 문자열 표현식에 조건절 명시 (가장 명확한 방법) 사용</span></span><br><span class="line">(df.where(<span class="string">&quot;InvoiceNo = 536365&quot;</span>)</span><br><span class="line">  .show(<span class="number">5</span>, <span class="literal">false</span>))</span><br><span class="line"></span><br><span class="line">(df.where(<span class="string">&quot;InvoiceNo &lt;&gt; 536365&quot;</span>)</span><br><span class="line">  .show(<span class="number">5</span>, <span class="literal">false</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// +---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+</span></span><br><span class="line"><span class="comment">// |InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |</span></span><br><span class="line"><span class="comment">// +---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+</span></span><br><span class="line"><span class="comment">// |536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |2010-12-01 08:26:00|2.55     |17850.0   |United Kingdom|</span></span><br><span class="line"><span class="comment">// |536365   |71053    |WHITE METAL LANTERN                |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|</span></span><br><span class="line"><span class="comment">// |536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |2010-12-01 08:26:00|2.75     |17850.0   |United Kingdom|</span></span><br><span class="line"><span class="comment">// |536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|</span></span><br><span class="line"><span class="comment">// |536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|</span></span><br><span class="line"><span class="comment">// +---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// +---------+---------+-----------------------------+--------+-------------------+---------+----------+--------------+</span></span><br><span class="line"><span class="comment">// |InvoiceNo|StockCode|Description                  |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |</span></span><br><span class="line"><span class="comment">// +---------+---------+-----------------------------+--------+-------------------+---------+----------+--------------+</span></span><br><span class="line"><span class="comment">// |536366   |22633    |HAND WARMER UNION JACK       |6       |2010-12-01 08:28:00|1.85     |17850.0   |United Kingdom|</span></span><br><span class="line"><span class="comment">// |536366   |22632    |HAND WARMER RED POLKA DOT    |6       |2010-12-01 08:28:00|1.85     |17850.0   |United Kingdom|</span></span><br><span class="line"><span class="comment">// |536367   |84879    |ASSORTED COLOUR BIRD ORNAMENT|32      |2010-12-01 08:34:00|1.69     |13047.0   |United Kingdom|</span></span><br><span class="line"><span class="comment">// |536367   |22745    |POPPY&#x27;S PLAYHOUSE BEDROOM    |6       |2010-12-01 08:34:00|2.1      |13047.0   |United Kingdom|</span></span><br><span class="line"><span class="comment">// |536367   |22748    |POPPY&#x27;S PLAYHOUSE KITCHEN    |6       |2010-12-01 08:34:00|2.1      |13047.0   |United Kingdom|</span></span><br><span class="line"><span class="comment">// +---------+---------+-----------------------------+--------+-------------------+---------+----------+--------------+</span></span><br></pre></td></tr></table></figure>
</details>
</li>
</ul>
</li>
<li><p>불리언 표현식 사용하는 경우</p>
<ul>
<li>항상 모든 표현식을 <code>and</code> 메서드로 묶어 차례대로 필터 적용 해야 함</li>
<li>스파크 내부적으로 필터 사이에 <code>and</code> 구문 추가 =&gt; 모든 필터를 하나의 문장으로 변환하여 <strong>동시에 모든 필터 처리</strong></li>
<li><code>and</code> 구문 사용 시<ul>
<li><code>and</code> 구문으로 조건문을 만들 수는 있으나,</li>
<li>차례대로 조건 나열하는게 가독성이 좋음</li>
</ul>
</li>
<li><code>or</code> 구문 사용시<ul>
<li>반드시 동일한 구문에 조건 정의해야 함</li>
</ul>
</li>
</ul>
</li>
<li><p>불리언 표현식은…</p>
<ul>
<li>필터링 조건에만 사용? =&gt; 🙅🏻‍♀️. DataFrame 필터링도 가능</li>
<li>반드시 표현식으로 정의해야? =&gt; 🙅🏻‍♀️. 별도 작업없이 컬럼명만 사용해서 정의도 가능</li>
<li>사실 SQL로 표현하는게 더 익숙할지도.. (성능저하 X)</li>
</ul>
</li>
<li><p>NULL 값 데이터 처리?</p>
<ul>
<li>=&gt; <strong>null-safe</strong> 동치(equivalence) 테스트</li>
<li>ex. <code>df.where(col(&quot;Description&quot;).eqNullSafe(&quot;hello&quot;)).show()</code></li>
</ul>
</li>
<li><p>SQL의 <code>IS [NOT] DISTINCT FROM</code> 구문</p>
<ul>
<li>과 동일한 기능? 이 뭘 말하나..</li>
<li>since Spark 2.3 (<a target="_blank" rel="noopener" href="https://bit.ly/2x47Obk">참고</a>)</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">[6.3-2] 예제 펼치기 </summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> priceFilter = col(<span class="string">&quot;UnitPrice&quot;</span>) &gt; <span class="number">600</span></span><br><span class="line"><span class="keyword">val</span> descripFilter = col(<span class="string">&quot;Description&quot;</span>).contains(<span class="string">&quot;POSTAGE&quot;</span>)</span><br><span class="line">(df.where(col(<span class="string">&quot;StockCode&quot;</span>).isin(<span class="string">&quot;DOT&quot;</span>)).where(priceFilter.or(descripFilter))</span><br><span class="line">  .show())</span><br><span class="line"><span class="comment">// priceFilter: org.apache.spark.sql.Column = (UnitPrice &gt; 600)</span></span><br><span class="line"><span class="comment">// descripFilter: org.apache.spark.sql.Column = contains(Description, POSTAGE)</span></span><br><span class="line"><span class="comment">// +---------+---------+--------------+--------+-------------------+---------+----------+--------------+</span></span><br><span class="line"><span class="comment">// |InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|</span></span><br><span class="line"><span class="comment">// +---------+---------+--------------+--------+-------------------+---------+----------+--------------+</span></span><br><span class="line"><span class="comment">// |   536544|      DOT|DOTCOM POSTAGE|       1|2010-12-01 14:32:00|   569.77|      null|United Kingdom|</span></span><br><span class="line"><span class="comment">// |   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      null|United Kingdom|</span></span><br><span class="line"><span class="comment">// +---------+---------+--------------+--------+-------------------+---------+----------+--------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- SQL (동일 표현)</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> dfTable <span class="keyword">WHERE</span> StockCode <span class="keyword">in</span> (&quot;DOT&quot;) <span class="keyword">AND</span>(UnitPrice <span class="operator">&gt;</span> <span class="number">600</span> <span class="keyword">OR</span></span><br><span class="line">    instr(Description, &quot;POSTAGE&quot;) <span class="operator">&gt;=</span> <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DataFrame 필터링 예제</span></span><br><span class="line"><span class="keyword">val</span> <span class="type">DOTCodeFilter</span> = col(<span class="string">&quot;StockCode&quot;</span>) === <span class="string">&quot;DOT&quot;</span></span><br><span class="line"><span class="keyword">val</span> priceFilter = col(<span class="string">&quot;UnitPrice&quot;</span>) &gt; <span class="number">600</span></span><br><span class="line"><span class="keyword">val</span> descripFilter = col(<span class="string">&quot;Description&quot;</span>).contains(<span class="string">&quot;POSTAGE&quot;</span>)</span><br><span class="line">(df.withColumn(<span class="string">&quot;isExpensive&quot;</span>, <span class="type">DOTCodeFilter</span>.and(priceFilter.or(descripFilter)))</span><br><span class="line">  .where(<span class="string">&quot;isExpensive&quot;</span>)</span><br><span class="line">  .select(<span class="string">&quot;unitPrice&quot;</span>, <span class="string">&quot;isExpensive&quot;</span>).show(<span class="number">5</span>))</span><br><span class="line"><span class="comment">// DOTCodeFilter: org.apache.spark.sql.Column = (StockCode = DOT)</span></span><br><span class="line"><span class="comment">// priceFilter: org.apache.spark.sql.Column = (UnitPrice &gt; 600)</span></span><br><span class="line"><span class="comment">// descripFilter: org.apache.spark.sql.Column = contains(Description, POSTAGE)</span></span><br><span class="line"><span class="comment">// +---------+-----------+</span></span><br><span class="line"><span class="comment">// |unitPrice|isExpensive|</span></span><br><span class="line"><span class="comment">// +---------+-----------+</span></span><br><span class="line"><span class="comment">// |   569.77|       true|</span></span><br><span class="line"><span class="comment">// |   607.49|       true|</span></span><br><span class="line"><span class="comment">// +---------+-----------+</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 동일하게 처리</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;expr, not, col&#125;</span><br><span class="line"></span><br><span class="line">(df.withColumn(<span class="string">&quot;isExpensive&quot;</span>, not(col(<span class="string">&quot;UnitPrice&quot;</span>).leq(<span class="number">250</span>)))</span><br><span class="line">  .filter(<span class="string">&quot;isExpensive&quot;</span>)</span><br><span class="line">  .select(<span class="string">&quot;Description&quot;</span>, <span class="string">&quot;UnitPrice&quot;</span>).show(<span class="number">5</span>))</span><br><span class="line">(df.withColumn(<span class="string">&quot;isExpensive&quot;</span>, expr(<span class="string">&quot;NOT UnitPrice &lt;= 250&quot;</span>))</span><br><span class="line">  .filter(<span class="string">&quot;isExpensive&quot;</span>)</span><br><span class="line">  .select(<span class="string">&quot;Description&quot;</span>, <span class="string">&quot;UnitPrice&quot;</span>).show(<span class="number">5</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- SQL (동일 표현)</span></span><br><span class="line"><span class="keyword">SELECT</span> UnitPrice, (StockCode <span class="operator">=</span> <span class="string">&#x27;DOT&#x27;</span> <span class="keyword">AND</span></span><br><span class="line">  (UnitPrice <span class="operator">&gt;</span> <span class="number">600</span> <span class="keyword">OR</span> instr(Description, &quot;POSTAGE&quot;) <span class="operator">&gt;=</span> <span class="number">1</span>)) <span class="keyword">as</span> isExpensive</span><br><span class="line"><span class="keyword">FROM</span> dfTable</span><br><span class="line"><span class="keyword">WHERE</span> (StockCode <span class="operator">=</span> <span class="string">&#x27;DOT&#x27;</span> <span class="keyword">AND</span></span><br><span class="line">       (UnitPrice <span class="operator">&gt;</span> <span class="number">600</span> <span class="keyword">OR</span> instr(Description, &quot;POSTAGE&quot;) <span class="operator">&gt;=</span> <span class="number">1</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</details>

<h3 id="6-4-수치형-데이터-타입-다루기"><a href="#6-4-수치형-데이터-타입-다루기" class="headerlink" title="6.4 수치형 데이터 타입 다루기"></a>6.4 수치형 데이터 타입 다루기</h3><ul>
<li><code>count()</code> <ul>
<li>빅데이터 처리 시, 필터링 다음으로 많이 수행하는 작업</li>
<li>수치형 데이터 타입을 사용한 연산 방식 정의</li>
</ul>
</li>
<li>자주 사용하는 수치형 함수<ul>
<li><code>pow(밑, 지수)</code> (거듭제곱)</li>
<li><code>round()</code> (반올림), <code>bround()</code> (내림)</li>
<li><code>corr()</code> =&gt; 피어슨 상관계수 계산 (= 두 컬럼의 상관관계)</li>
<li><code>describe()</code> =&gt; 관련 컬럼에 대한 집계(count), 평균(mean), 표준편차(stddev), 최솟값(min), 최댓값(max) 등 계산<ul>
<li>하나 이상의 컬럼에대한 요약 통계 계산</li>
<li>그러나 콘솔 확인용으로만 사용해야함 (통계 스키마는 변경 될 수 있음)</li>
<li>정확한 수치 필요 시, 해당 함수 임포트해서 적용하는 방식으로 <strong>직접 집계</strong></li>
</ul>
</li>
</ul>
</li>
<li><strong>StatFunction</strong> 패키지 =&gt; 다양한 통계 함수 제공<ul>
<li>다양한 통계값 계산에 사용하는 DataFrame 메서드 =&gt; <code>df.stat</code> 으로 접근</li>
<li><code>approxQuantile()</code> : 데이터 백분위수 계산 (정확하게 또는 근사치로?)</li>
<li><code>crosstab()</code> : 교차표(cross-tabulation) 확인</li>
<li><code>freqItems()</code> : 자주 사용하는 항목 쌍 확인<ul>
<li>crosstab, freqItems 등은 결과가 너무 크면 다 출력 X</li>
</ul>
</li>
<li><code>monotonically_increasing_id()</code> : 모든 로우에 고유 ID 값 추가 (0 ~ )</li>
</ul>
</li>
<li>스파크 새로운 버전 나올 때마다 새로운 함수 생김<ul>
<li>=&gt; 스파크 공식 문서 참조</li>
<li>예를 들자면 <code>ran()</code>, <code>randn()</code> (임의 데이터 생성 함수) ?</li>
<li>최신 버전 StatFunction 패키지는 여러 고급 기법 관련 함수 제공하기도<ul>
<li>bloom 필터링, scketching algorithms ..</li>
<li>자세한 내용은 <a target="_blank" rel="noopener" href="http://bit.ly/2ptAiY2">API docs</a></li>
<li>(사실 현시점 최신버전은 아니고 책기준 최신 2.2 버전인 듯)</li>
</ul>
</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">[6.4] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;expr, pow&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 두 컬럼 모두 수치형 =&gt; 곱셈 연산 가능 (+ 덧셈, 뺄셈)</span></span><br><span class="line"><span class="keyword">val</span> fabricatedQuantity = pow(col(<span class="string">&quot;Quantity&quot;</span>) * col(<span class="string">&quot;UnitPrice&quot;</span>), <span class="number">2</span>) + <span class="number">5</span></span><br><span class="line">df.select(expr(<span class="string">&quot;CustomerId&quot;</span>), fabricatedQuantity.alias(<span class="string">&quot;realQuantity&quot;</span>)).show(<span class="number">2</span>)</span><br><span class="line"><span class="comment">// +----------+------------------+</span></span><br><span class="line"><span class="comment">// |CustomerId|      realQuantity|</span></span><br><span class="line"><span class="comment">// +----------+------------------+</span></span><br><span class="line"><span class="comment">// |   17850.0|239.08999999999997|</span></span><br><span class="line"><span class="comment">// |   17850.0|          418.7156|</span></span><br><span class="line"><span class="comment">// +----------+------------------+</span></span><br><span class="line"></span><br><span class="line">df.selectExpr(</span><br><span class="line">  <span class="string">&quot;CustomerId&quot;</span>,</span><br><span class="line">  <span class="string">&quot;(POWER((Quantity * UnitPrice), 2.0) + 5) as realQuantity&quot;</span>).show(<span class="number">2</span>)</span><br><span class="line"><span class="comment">// +----------+------------------+</span></span><br><span class="line"><span class="comment">// |CustomerId|      realQuantity|</span></span><br><span class="line"><span class="comment">// +----------+------------------+</span></span><br><span class="line"><span class="comment">// |   17850.0|239.08999999999997|</span></span><br><span class="line"><span class="comment">// |   17850.0|          418.7156|</span></span><br><span class="line"><span class="comment">// +----------+------------------+</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 반올림(round) 예제</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;round, bround&#125;</span><br><span class="line">df.select(round(col(<span class="string">&quot;UnitPrice&quot;</span>), <span class="number">1</span>).alias(<span class="string">&quot;rounded&quot;</span>), col(<span class="string">&quot;UnitPrice&quot;</span>)).show(<span class="number">5</span>)</span><br><span class="line"><span class="comment">// +-------+---------+</span></span><br><span class="line"><span class="comment">// |rounded|UnitPrice|</span></span><br><span class="line"><span class="comment">// +-------+---------+</span></span><br><span class="line"><span class="comment">// |    2.6|     2.55|</span></span><br><span class="line"><span class="comment">// |    3.4|     3.39|</span></span><br><span class="line"><span class="comment">// |    2.8|     2.75|</span></span><br><span class="line"><span class="comment">// |    3.4|     3.39|</span></span><br><span class="line"><span class="comment">// |    3.4|     3.39|</span></span><br><span class="line"><span class="comment">// +-------+---------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 내림(bround) 예제</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.lit</span><br><span class="line">df.select(round(lit(<span class="string">&quot;2.5&quot;</span>)), bround(lit(<span class="string">&quot;2.5&quot;</span>))).show(<span class="number">2</span>)</span><br><span class="line"><span class="comment">// +-------------+--------------+</span></span><br><span class="line"><span class="comment">// |round(2.5, 0)|bround(2.5, 0)|</span></span><br><span class="line"><span class="comment">// +-------------+--------------+</span></span><br><span class="line"><span class="comment">// |          3.0|           2.0|</span></span><br><span class="line"><span class="comment">// |          3.0|           2.0|</span></span><br><span class="line"><span class="comment">// +-------------+--------------+</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 피어슨 상관계수 계산 예제</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;corr&#125;</span><br><span class="line">df.stat.corr(<span class="string">&quot;Quantity&quot;</span>, <span class="string">&quot;UnitPrice&quot;</span>)</span><br><span class="line">df.select(corr(<span class="string">&quot;Quantity&quot;</span>, <span class="string">&quot;UnitPrice&quot;</span>)).show()</span><br><span class="line"><span class="comment">// res52: Double = -0.04112314436835551</span></span><br><span class="line"><span class="comment">// +-------------------------+</span></span><br><span class="line"><span class="comment">// |corr(Quantity, UnitPrice)|</span></span><br><span class="line"><span class="comment">// +-------------------------+</span></span><br><span class="line"><span class="comment">// |     -0.04112314436835551|</span></span><br><span class="line"><span class="comment">// +-------------------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- SQL (동일 표현)</span></span><br><span class="line"><span class="keyword">SELECT</span> customerId, (<span class="built_in">POWER</span>((Quantity <span class="operator">*</span> UnitPrice), <span class="number">2.0</span>) <span class="operator">+</span> <span class="number">5</span>) <span class="keyword">as</span> realQuantity</span><br><span class="line"><span class="keyword">FROM</span> dfTable</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> round(<span class="number">2.5</span>), bround(<span class="number">2.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">corr</span>(Quantity, UnitPrice) <span class="keyword">FROM</span> dfTable</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 콘솔용 요약 통계 (describe)</span></span><br><span class="line">df.describe().show()</span><br><span class="line"><span class="comment">// +-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+</span></span><br><span class="line"><span class="comment">// |summary|        InvoiceNo|         StockCode|         Description|          Quantity|         UnitPrice|        CustomerID|       Country|</span></span><br><span class="line"><span class="comment">// +-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+</span></span><br><span class="line"><span class="comment">// |  count|             3108|              3108|                3098|              3108|              3108|              1968|          3108|</span></span><br><span class="line"><span class="comment">// |   mean| 536516.684944841|27834.304044117645|                null| 8.627413127413128| 4.151946589446603|15661.388719512195|          null|</span></span><br><span class="line"><span class="comment">// | stddev|72.89447869788873|17407.897548583845|                null|26.371821677029203|15.638659854603892|1854.4496996893627|          null|</span></span><br><span class="line"><span class="comment">// |    min|           536365|             10002| 4 PURPLE FLOCK D...|               -24|               0.0|           12431.0|     Australia|</span></span><br><span class="line"><span class="comment">// |    max|          C536548|              POST|ZINC WILLIE WINKI...|               600|            607.49|           18229.0|United Kingdom|</span></span><br><span class="line"><span class="comment">// +-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 직접 집계 필요 시 =&gt; 함수 임포트</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;count, mean, stddev_pop, min, max&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// StatFunction 예제</span></span><br><span class="line"><span class="comment">// approxQuantile() : 데이터 백분위수 계산</span></span><br><span class="line"><span class="keyword">val</span> colName = <span class="string">&quot;UnitPrice&quot;</span></span><br><span class="line"><span class="keyword">val</span> quantileProbs = <span class="type">Array</span>(<span class="number">0.5</span>)</span><br><span class="line"><span class="keyword">val</span> relError = <span class="number">0.05</span></span><br><span class="line">df.stat.approxQuantile(<span class="string">&quot;UnitPrice&quot;</span>, quantileProbs, relError)</span><br><span class="line"><span class="comment">// res61: Array[Double] = Array(2.51)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// crosstab() : 교차표 확인</span></span><br><span class="line">df.stat.crosstab(<span class="string">&quot;StockCode&quot;</span>, <span class="string">&quot;Quantity&quot;</span>).show()</span><br><span class="line"><span class="comment">// +------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+</span></span><br><span class="line"><span class="comment">// |StockCode_Quantity| -1|-10|-12| -2|-24| -3| -4| -5| -6| -7|  1| 10|100| 11| 12|120|128| 13| 14|144| 15| 16| 17| 18| 19|192|  2| 20|200| 21|216| 22| 23| 24| 25|252| 27| 28|288|  3| 30| 32| 33| 34| 36|384|  4| 40|432| 47| 48|480|  5| 50| 56|  6| 60|600| 64|  7| 70| 72|  8| 80|  9| 96|</span></span><br><span class="line"><span class="comment">// +------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+</span></span><br><span class="line"><span class="comment">// |             22578|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             21327|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             22064|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             21080|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|</span></span><br><span class="line"><span class="comment">// |             22219|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  3|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             21908|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             22818|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |           15056BL|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             72817|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             22545|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             22988|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             22274|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             20750|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |            82616C|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             21703|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             22899|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             22379|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             22422|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             22769|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// |             22585|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|</span></span><br><span class="line"><span class="comment">// +------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// freqItems() : 자주 사용하는 항목 쌍 확인</span></span><br><span class="line">df.stat.freqItems(<span class="type">Seq</span>(<span class="string">&quot;StockCode&quot;</span>, <span class="string">&quot;Quantity&quot;</span>)).show()</span><br><span class="line"><span class="comment">// +--------------------+--------------------+</span></span><br><span class="line"><span class="comment">// | StockCode_freqItems|  Quantity_freqItems|</span></span><br><span class="line"><span class="comment">// +--------------------+--------------------+</span></span><br><span class="line"><span class="comment">// |[90214E, 20728, 2...|[200, 128, 23, 32...|</span></span><br><span class="line"><span class="comment">// +--------------------+--------------------+</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// monotonically_increasing_id() : 로우에 고유 ID 값 추가</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.monotonically_increasing_id</span><br><span class="line">df.select(monotonically_increasing_id()).show(<span class="number">2</span>)</span><br><span class="line"><span class="comment">// +-----------------------------+</span></span><br><span class="line"><span class="comment">// |monotonically_increasing_id()|</span></span><br><span class="line"><span class="comment">// +-----------------------------+</span></span><br><span class="line"><span class="comment">// |                            0|</span></span><br><span class="line"><span class="comment">// |                            1|</span></span><br><span class="line"><span class="comment">// +-----------------------------+</span></span><br></pre></td></tr></table></figure>
</details>

<h3 id="6-5-문자열-데이터-타입-다루기"><a href="#6-5-문자열-데이터-타입-다루기" class="headerlink" title="6.5 문자열 데이터 타입 다루기"></a>6.5 문자열 데이터 타입 다루기</h3><ul>
<li>문자열 다루기 = 거의 모든 데이터 처리 과정에서 발생<ul>
<li>로그 파일에 정규 표현식을 사용한 데이터 추출, 데이터 치환, 문자열 존재 여부, 대/소문자 변환 처리 등</li>
</ul>
</li>
<li>대소문자 변환 작업<ul>
<li><code>initcap()</code> =&gt; 공백으로 구분된 모든 단어의 첫 글자 대문자로 변환</li>
<li><code>lower()</code> (전체 소문자로 변환) / <code>upper()</code> (전체 대문자로 변환)</li>
<li><code>lpad()</code>, <code>ltrim()</code>, <code>rpad()</code>, <code>rtrim()</code>, <code>trim()</code>=&gt; 문자열 주변 공백 제거/추가</li>
</ul>
</li>
<li>정규표현식<ul>
<li>스파크는 <strong>자바 정규 표현식 문법</strong> 사용</li>
<li><code>regexp_extract()</code>, <code>regexp_replace()</code> =&gt; 값 추출 및 치환</li>
<li><code>translate(column, from_string, to_string)</code> 사용한 치환 가능</li>
<li>값 존재 여부 확인 방법?<ul>
<li>스칼라 사용 시 <code>contains()</code> 사용</li>
<li>파이썬, SQL 사용 시 <code>instr()</code> 사용</li>
</ul>
</li>
<li>동적으로 인수의 개수가 변하는 상황에서는<ul>
<li>스칼라 고유 기능 <code>varargs()</code> 사용</li>
<li>파이썬은 <code>locate()</code> (문자열 위치를 정수로 반환. 위치는 1 ~) + 위치 정보 불리언으로 변환</li>
</ul>
</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">[6.5] 예제 펼치기</summary>

</details>

<h3 id="6-6-날짜와-타임스탬프-데이터-타입-다루기"><a href="#6-6-날짜와-타임스탬프-데이터-타입-다루기" class="headerlink" title="6.6 날짜와 타임스탬프 데이터 타입 다루기"></a>6.6 날짜와 타임스탬프 데이터 타입 다루기</h3><ul>
<li>날짜/시간 사용 시 시간대 (timezone) 와 포맷의 유효성 확인 필요<ul>
<li>=&gt; 스파크는 두 가지 정보만 집중적으로 관리</li>
<li><strong>날짜</strong> (date) &amp; <strong>타임스탬프</strong> (timestamp)</li>
<li>inferSchema 옵션 활성화된 경우, 두 정보를 포함해 데이터 타입을 최대한 정확히 식별</li>
<li>스파크는 특정 날짜 포맷 명시 없이도 자체적으로 식별</li>
</ul>
</li>
<li>날짜, 시간을 문자열로 저장 &lt;-&gt; 런타임에 날짜 타입으로 변환<ul>
<li>텍스트, CSV 파일 다룰 시 많이 발생하는 방식</li>
<li>스파크 2.1 이하) 시간대 미지정 시, 시스템 시간대 기준으로 파싱<ul>
<li>시간대 설정? =&gt; <code>spark.conf.sessionLocalTimeZone</code> 속성을 로컬 시간대로 지정 - <a target="_blank" rel="noopener" href="https://bit.ly/2NcW6p2">Java TimeZone 포맷</a> 따름)</li>
</ul>
</li>
<li>스파크 2.3 이상) <code>spark.conf.set(&quot;spark.sql.session.timeZone&quot;, &quot;UTC&quot;)</code> 으로 사용 가능</li>
</ul>
</li>
<li>TimestampType 클래스는 초 단위 정밀도까지만 지원<ul>
<li>밀리세컨드(ms), 마이크로세컨드(μs) 지원 X =&gt; 필요 시 Long 데이터타입 사용해서 우회</li>
<li>특이한 포맷의 날짜/시간 데이터를 다뤄야한다면</li>
<li>각 단계별 데이터타입과 포맷 정확히 파악 후 트랜스포메이션 적용 해야함</li>
</ul>
</li>
<li>스파크는 특정 시점에 데이터 포맷이 특이하게 변할 수 있다<ul>
<li>싫다면 파싱이나 변환 작업 필요</li>
<li>스파크는 자바의 날짜와 타임스탬프 사용 (표준 체계)</li>
</ul>
</li>
<li>두 날짜 사이 차이 구하기<ul>
<li><code>datediff()</code> : 두 날짜 사이 일 수 반환</li>
<li><code>months_between()</code> : 두 날짜 사이 개월 수 반환</li>
</ul>
</li>
<li>날짜 비교<ul>
<li>올바른 포맷과 타입 사용 시 매우 쉬움</li>
<li>날짜나 타임스탬프 타입 사용 or ‘yyy-MM-dd’ 포맷에 맞는 문자열 지정</li>
<li><code>to_date()</code> : 문자열 =&gt; 날짜로 변환 (option. 날짜 포맷 지정 가능)<ul>
<li>날짜 포맷 : 자바의 <a target="_blank" rel="noopener" href="https://bit.ly/2Mz21Qc">SimpleDateFormat 클래스 지원 포맷 </a>사용</li>
</ul>
</li>
<li><code>to_timestamp()</code> : 날짜 포맷 필수 (미지정시 ‘yyyy-MM-dd HH:mm:ss’ 포맷 default)</li>
</ul>
</li>
<li>날짜 파싱 실패?<ul>
<li>=&gt; <strong>null 반환</strong> (에러 X)</li>
<li>예상치 못한 포맷의 데이터가 나타날 수 있으므로 디버깅 어려움</li>
<li>문제 회피할 수 있는 방식<ul>
<li>1. 자바 <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html">SimpleDateFormat</a> 표준에 맞춰 날짜 포맷 지정</li>
<li>2. <code>to_date()</code>, <code>to_timestamp()</code> 사용</li>
</ul>
</li>
<li>암시적 형변환(implicit type casting)은 위험 =&gt; 명시적으로 데이터 타입 변환해서 사용할 것</li>
</ul>
</li>
</ul>
<h3 id="6-7-null-값-다루기"><a href="#6-7-null-값-다루기" class="headerlink" title="6.7 null 값 다루기"></a>6.7 null 값 다루기</h3><ul>
<li>DataFrame 에서 빈 값은 <strong>NULL</strong> 로 표현하는게 좋다<ul>
<li>스파크에서는 null 을 사용해야 최적화 수행 (빈 문자열 X, 대체값 X)</li>
</ul>
</li>
<li>DataFrame 에서 null 을 다루는 기본 방식 =&gt; <code>.na</code><ul>
<li>DataFrame의 하위 패키지</li>
<li>연산 수행 중 null 값 제어 방식을 명시적으로 지정하는 함수는 =&gt; 5.4.15 로우정렬하기 / 6.3 불리언 데이터 타입 다루기 참조</li>
</ul>
</li>
<li>null 값을 다루는 두가지 방식<ul>
<li>명시적으로 null 값 제거</li>
<li>전역 or 컬럼 단위로 null 값을 특정 값으로 채우기</li>
</ul>
</li>
</ul>
<blockquote>
<p>null 값은 명시적으로 사용 권장.<br>그러나 null 값을 허용하지 않는 컬럼 선언해도 <strong>강제성 없음</strong></p>
<ul>
<li>즉, notnull 컬럼이여도 null 값이 있을 수 있다</li>
<li>nullable 속성은 스파크 SQL 옵티마이저가 해당 컬럼을 제어하는 동작을 단순하게 도울 뿐</li>
</ul>
</blockquote>
<ul>
<li><p><code>coalesce()</code></p>
<ul>
<li>인수의 여러 컬럼 중 null 이 아닌 첫번째 값 반환</li>
<li>모든 컬럼이 null이 아닌 값을 가지면 첫 번째 컬럼 값 반환<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.coalesce</span><br><span class="line"></span><br><span class="line"><span class="comment">// Description 컬럼 값 null 체크</span></span><br><span class="line"><span class="comment">//  1. null이면 CustomerId 값 반환</span></span><br><span class="line"><span class="comment">//  2. null이 아니면 Description 컬럼 값 반환</span></span><br><span class="line">df.select(coalesce(col(<span class="string">&quot;Description&quot;</span>), col(<span class="string">&quot;CustomerId&quot;</span>))).show()</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>SQL 함수</p>
<ul>
<li><code>ifnull()</code> : 첫 번째 값이 null이면 두 번째 값 반환, null이 아니면 첫 번째 값 반환</li>
<li><code>nullif()</code> : 두 값이 같으면 null 반환, 다르면 첫 번째 값 반환</li>
<li><code>nvl()</code> : 첫 번째 값이 null이면 두 번째 값 반환, null이 아니면 첫 번째 값 반환</li>
<li><code>nvl2()</code> : 첫 번째 값이 null이 아니면 두 번째 값 반환, null이면 세 번째 값 반환<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 이해하는 용도 like this</span></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">ifnull</span><span class="params">(first: <span class="type">Any</span>, default: <span class="type">Any</span>)</span></span> = <span class="keyword">if</span> (first != <span class="literal">null</span>) first <span class="keyword">else</span> default</span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">nullif</span><span class="params">(first: <span class="type">Any</span>, second: <span class="type">Any</span>)</span></span> = <span class="keyword">if</span> (first != second) first <span class="keyword">else</span> <span class="literal">null</span></span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">nvl</span><span class="params">(first: <span class="type">Any</span>, default: <span class="type">Any</span>)</span></span> = <span class="keyword">if</span> (first != <span class="literal">null</span>) first <span class="keyword">else</span> default</span><br><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">nvl2</span><span class="params">(first: <span class="type">Any</span>, notnull_return: <span class="type">Any</span>, null_return: <span class="type">Any</span>)</span></span> = <span class="keyword">if</span> (first != <span class="literal">null</span>) notnull_return <span class="keyword">else</span> null_return</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p><code>drop()</code></p>
<ul>
<li>null 값을 가진 로우를 모든 로우 제거</li>
<li>인수<ul>
<li><code>any</code> (하나라도 null이면 제거) / <code>all</code> (모든 컬럼이 null 또는 NaN이면 제거)</li>
<li>배열 형태 컬럼도 인수로 전달 가능</li>
</ul>
</li>
<li>SQL 사용 시 컬럼별로 수행해야함</li>
</ul>
</li>
<li><p><code>fill()</code></p>
<ul>
<li>하나 이상의 컬럼을 특정 값으로 채움</li>
<li>인수<ul>
<li>채워넣을 값, 컬럽 집합으로 구성된 맵</li>
<li>컬럼명 배열로 인수 사용 시 다수 컬럼 적용 가능</li>
</ul>
</li>
<li>스칼라 Map 타입 사용도 인수로 가능 (key:value = 컬럼명:null값을 채울 값)</li>
</ul>
</li>
<li><p><code>relace()</code></p>
<ul>
<li>조건에 따라 다른 값으로 대체</li>
<li>변경하고자하는 값 == 원래 값 데이터 타입 같아야</li>
</ul>
</li>
</ul>
<h3 id="6-8-정렬하기"><a href="#6-8-정렬하기" class="headerlink" title="6.8 정렬하기"></a>6.8 정렬하기</h3><ul>
<li><code>asc_nulls_first()</code>, <code>desc_nulls_first()</code>, <code>asc_nulls_last()</code>, <code>desc_nulls_last()</code><ul>
<li>DataFrame 정렬 시 null 값 표시 기준 지정 가능</li>
</ul>
</li>
<li>(=&gt; <a href="https://minsw.github.io/2021/01/26/Spark-The-Definitive-Guide-5%EC%9E%A5/#15-%EB%A1%9C%EC%9A%B0-%EC%A0%95%EB%A0%AC%ED%95%98%EA%B8%B0">5.4.15 - 로우정렬하기</a> 참고)</li>
</ul>
<h3 id="6-9-복합-데이터-타입-다루기"><a href="#6-9-복합-데이터-타입-다루기" class="headerlink" title="6.9 복합 데이터 타입 다루기"></a>6.9 복합 데이터 타입 다루기</h3><ul>
<li>복합 데이터 타입 : 구조체 (struct), 배열 (array), 맵(map)</li>
<li>구조체 = DataFrame 내부의 DataFrame<ul>
<li>쿼리문에서 다수의 컬럼을 괄호로 묶어서 =&gt; 구조체 만듦</li>
<li>복합 데이터 타입을 가진 DataFrame 사용<ul>
<li>=&gt; 다른 DataFrame 조회하는것과 동일하게 사용 가능</li>
<li>차이점은 문법에 점 (.) 사용 or <code>getField()</code> 사용</li>
<li><code>*</code> 문자로 모든 값 조회 가능 (모든 컬럼을 최상위 수준으로 끌어올리기 가능?)</li>
</ul>
</li>
</ul>
</li>
<li>배열<ul>
<li>example) 해당하는 컬럼의 모든 단어를 하나의 로우로 변환</li>
<li><code>split(target, delimiter)</code> : 구분자 기준으로 나누어 배열로 변환<ul>
<li>복합 데이터 타입을 또 다른 컬럼처럼 다룰 수 있는 기능</li>
</ul>
</li>
<li>배열의 길이 : 배열 size 조회해서 길이 알 수 있음</li>
<li><code>array_contains()</code> : 배열에 특정 값 존재하는지 확인 가능<ul>
<li>하지만 시나리오 완성은 불가능</li>
</ul>
</li>
<li><code>explode(배열타입 칼럼)</code> : 인수의 컬럼 배열 갑셍 포함된 모든 값을 로우로 변환 (나머지 컬럼 값은 중복되어 표시)</li>
</ul>
</li>
<li>맵<ul>
<li><code>map()</code> + 키-값 쌍</li>
<li>적합한 키로 데이터 조회 가능, 없을 시 null 반환</li>
<li>map 타입 분해 -&gt; 컬럼 변환 가능</li>
</ul>
</li>
</ul>
<h3 id="6-10-JSON-다루기"><a href="#6-10-JSON-다루기" class="headerlink" title="6.10 JSON 다루기"></a>6.10 JSON 다루기</h3><ul>
<li>스파크에서 JSON 데이터 다루기 위한 고유 기능 제공<ul>
<li>문자열 형태 JSON 조작, JSON 파싱, JSON 객체로 변환 등</li>
</ul>
</li>
<li><code>get_json_object()</code><ul>
<li>JSON 객체 (딕셔너리, 배열) 인라인 쿼리로 조회 가능</li>
<li>중첩 없는 단일 JSON일 시, <code>json_tuble</code> 사용 가능</li>
</ul>
</li>
<li><code>to_json()</code> : StructType -&gt; JSON 문자열. 데이터 소스와 동일한 형태의 딕셔너리(맵) 인자로 사용 가능</li>
<li><code>from_json()</code> : JSON 문자열 -&gt; 객체. 단 스키마 지정 필수 (option. 맵 데이터 타입 옵션)</li>
</ul>
<h3 id="6-11-사용자-정의-함수"><a href="#6-11-사용자-정의-함수" class="headerlink" title="6.11 사용자 정의 함수"></a>6.11 사용자 정의 함수</h3><ul>
<li><strong>사용자 정의 함수</strong> (user defined function, <strong>UDF</strong>)<ul>
<li>스파크의 가장 강력한 기능 중 하나</li>
<li>파이썬, 스칼라, 외부 라이브러리등 사용 =&gt; 사용자가 원하는 형태로 트랜스포메이션 생성</li>
</ul>
</li>
<li>특징<ul>
<li>하나 이상의 컬럼을 입력/반환 가능</li>
<li>스파크 UDF는 다양한 언어로 개발 가능</li>
<li>레코드 별로 데이터를 처리하는 함수이므로, 독특하거나 도메인 특화 (DSL) 언어 사용 X</li>
<li>=&gt; 기본적으로 특정 SparkSession이나 Context에서 사용할 수 있게 <u>임시 함수 형태로 등록</u></li>
</ul>
</li>
<li>다양한 언어로 UDF 개발 가능<ul>
<li>그러나 언어별로 성능에 영향 존재<ul>
<li>예제 참고</li>
<li>함수를 만들고 모든 워커 노드에서 해당 함수를 사용할 수 있도록 스파크에 등록<ul>
<li>스파크는 드라이버에서 함수 직렬화 -&gt; 네트워크 통해서 모든 익스큐터 프로세스로 전달</li>
</ul>
</li>
<li>애초에 스칼라, 자바 사용 시 JVM 환경에서만 사용 가능 (성능 ↓)</li>
<li>파이썬 사용 시 모든 데이터를 직렬화하고, 파이썬 프로세스에 있는 데이터의 로우마다 함수 실행 및 JVM과 스파크에 처리 겨로가 반환<ul>
<li>직렬화 과정에서 부하 발생하고, 스파크에서 워커 메모리 관리의 어려움</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>기본은 사용자 정의 함수는 DataFrame에서만 사용 가능 (문자열 표현식 X)<ul>
<li>그러나, 사용자 정의 함수 -&gt; 스파크 SQL 함수 등록</li>
<li>모든 프로그래밍 언어와 SQL 에서 사용자 정의 함수 사용 가능. 우회적으로 사용 가능하지만 DataFrame 함수 대신 SQL 표현식으로 사용해야함 (변환 타입 지정 권!장!)</li>
</ul>
</li>
<li>사용자 정의 함수에서 선택적 값 반환<ul>
<li>파이썬 = <code>None</code> / 스칼라 = <code>Option</code> 반환</li>
</ul>
</li>
</ul>
<h3 id="6-12-Hive-UDF"><a href="#6-12-Hive-UDF" class="headerlink" title="6.12 Hive UDF"></a>6.12 Hive UDF</h3><ul>
<li>하이브 문법을 사용해서 만든 함수 =&gt; <strong>UDF</strong>, <strong>UDAF</strong> 사용 가능<ul>
<li>UDF (User Defined Function)</li>
<li>UDAF (User Defined Aggregate Function)</li>
</ul>
</li>
<li>단, 하이브 지원 기능 활성화 필요<ul>
<li><code>SparkSession.builder().enableHiveSupport()</code> 명시</li>
<li>하이브 지원 활성화 되면 SQL로 UDF 등록 가능</li>
<li>사전에 컴파일된 스칼라, 자바 패키지만 지원 (라이브러리 의존성 명시 필요)</li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- TEMPORARY 키워드 제거 시 =&gt; 하이브 메타스토어에 영구(permanent) 함수로 등록</span></span><br><span class="line"><span class="keyword">CREATE</span> TEMPORARY <span class="keyword">FUNCTION</span> myFunc <span class="keyword">AS</span> <span class="string">&#x27;com.organization.hive.udf.FunctionName&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="6-13-정리"><a href="#6-13-정리" class="headerlink" title="6.13 정리"></a>6.13 정리</h3><ul>
<li>스파크 SQL을 사용목적에 맞게 확장하는 방식<ul>
<li>간단한 함수만으로도 확장 가능 (DSL X)</li>
</ul>
</li>
<li>스파크 SQL은 복잡한 비즈니스 로직 구현에 사용할 수 있는 강력한 기능</li>
</ul>
<h3 id="📒-단어장"><a href="#📒-단어장" class="headerlink" title="📒 단어장"></a>📒 단어장</h3></div><p class="post-tags"><i class="fa fa-tags" aria-hidden="true"></i><a href="/tags/study/">#study</a><a href="/tags/book/">#book</a><a href="/tags/spark/">#spark</a><a href="/tags/apache/">#apache</a></p></article></div><footer><div class="paginator"><a class="prev" href="/2021/02/03/Spark-The-Definitive-Guide-7%EC%9E%A5/">PREV</a><a class="next" href="/2021/01/26/Spark-The-Definitive-Guide-5%EC%9E%A5/">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'minsw-github-io';
var disqus_identifier = '2021/02/02/Spark-The-Definitive-Guide-6장/';
var disqus_title = '&amp;#039;Spark The Definitive Guide&amp;#039; 6장 - 데이터 타입 (비)공식 가이드북';
var disqus_url = 'https://minsw.github.io/2021/02/02/Spark-The-Definitive-Guide-6장/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//#{theme.disqus}.disqus.com/count.js" async></script><div class="copyright"><p>© 2018 - 2021 <a href="https://minsw.github.io">Lukka Min</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-143001954-1",'auto');ga('send','pageview');</script><link rel="stylesheet" href="//cdn.datatables.net/1.10.7/css/jquery.dataTables.min.css" media="screen" type="text/css"><script src="//cdn.datatables.net/1.10.7/js/jquery.dataTables.min.js"></script><script>$(function(){$('.datatable').dataTable( {"order": [[ 0, "desc" ]],"iDisplayLength": -1,"lengthMenu": [[10, 25, 50, -1], [10, 25, 50, "All"]]} );});</script></body></html>