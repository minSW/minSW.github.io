<!DOCTYPE html><html lang="ko"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> &#039;Spark The Definitive Guide&#039; 7장 - 집계해라 애송이 · Look out</title><meta name="description" content="&amp;#039;Spark The Definitive Guide&amp;#039; 7장 - 집계해라 애송이 - Lukka Min"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/cover.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"><link rel="search" type="application/opensearchdescription+xml" href="https://minsw.github.io/atom.xml" title="Look out"><script src="//code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/feed.xml" title="Look out" type="application/atom+xml">
</head><body><div class="wrap"><header><a class="logo-link" href="/"><img src="/cover.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a class="nav-list-link" href="/" target="_self">BLOG</a></li><li class="nav-list-item"><a class="nav-list-link" href="/archives/" target="_self">ARCHIVE</a></li><li class="nav-list-item"><a class="nav-list-link" href="/tags/" target="_self">TAG</a></li><li class="nav-list-item"><a class="nav-list-link" href="https://github.com/minSW" target="_blank">GITHUB</a></li></ul></header><main class="container"></main><div class="post"><article class="post-block"><h1 class="post-title">&#039;Spark The Definitive Guide&#039; 7장 - 집계해라 애송이</h1><div class="post-info">2021년 2월 3일<span class="categories"><i class="fa fa-bookmark" aria-hidden="true"></i></span><a class="post-category" href="/categories/spark/">#spark</a></div><div class="post-content"><br/>

<p style="color:lightgray">벌써부터 슬슬 포스트 포멧 헷갈리기 시작하죠? 망했죠?<br/>
나중에 한번에 맞춰야지 생각해놓고 절대 수정안하죠? ㅎ..</p>

<br/>

<img width="300" alt="counting" src="https://user-images.githubusercontent.com/26691216/106792995-3b405280-669a-11eb-9f64-fc4d576200cd.gif">

<center><h2>_ _ _</h2></center>

<br/>

<hr>
<h1 id="CHAPTER-7-집계-연산"><a href="#CHAPTER-7-집계-연산" class="headerlink" title="CHAPTER 7 집계 연산"></a>CHAPTER 7 집계 연산</h1><p><em>집계(aggregation)은 무언갈 함께 모으는 행위이며 빅데이터 분석의 초석이다.</em></p>
<p>스파크는 모든 데이터 타입 다루는 것 + 다음과 같은 <strong>그룹화 데이터 타입</strong> 생성 가능하고,<br>지정된 집계 함수에 따라 그룹화된 결과는 RelationalGroupedDataset 을 반환.</p>
<blockquote>
<ul>
<li>select 구문에서 집계 수행, DataFrame 전체 데이터 요약 (가장 간단한 그룹화)</li>
<li>‘group by’ : 하나 이상의 키 지정. 다른 집계 함수 사용해서 값을 가진 컬럼 변환 가능</li>
<li>‘윈도우(window)’ : 하나 이상의 키 지정. 다른 집계 함수로 컬럼 변환 가능. + 단, 함수 입력으로 사용할 로우는 현재 로우와 <strong>연관성</strong> 있어야 함</li>
<li>‘그룹화 셋(grouping set)’ : 서로 다른 레벨 값 집계 (SQL, DataFrame의 롤업, 큐브)</li>
<li>‘롤업(rollup)’ : 하나 이상의 키 지정. 다른 집계 함수로 컬럼 변환 가능. + <strong>계층적으로 요약된 값</strong> 추출</li>
<li>‘큐브(cube)’ : 하나 이상의 키 지정. 다른 집계 함수로 컬럼 변환 가능. + <strong>모든 컬럼 조합에 대한 요약 값</strong> 계산</li>
</ul>
<p><i style="color:lightgray">(=&gt; 사실상 7장 요약)</i> </p>
</blockquote>
<p>📌 중요한 건, <strong>어떤 결과를 만들지</strong> 정확히 파악해야 한다는 것.<br>(정확한 답 계산 = 높은 비용 요구 → 빅데이터의 경우 근사치가 효율적일 수 있음)</p>
<!-- 
count 예제.. (데이터셋 크기 출력 및 캐싱용도)
이질적으로 느껴질 수 있음. 왜나면...
- 함수가 아닌 메서드 형태
- 트랜스포메이션같은 지연 연산이아닌 즉시 연산(액션)
-->

<h3 id="7-1-집계-함수"><a href="#7-1-집계-함수" class="headerlink" title="7.1 집계 함수"></a>7.1 집계 함수</h3><ul>
<li>모든 집계는 특별한 경우를 제외하고는 <strong>함수</strong> 사용<ul>
<li>=&gt; <strong>집계 함수</strong> (<a target="_blank" rel="noopener" href="https://bit.ly/2tRMYus">org.apache.spark.sql.functions</a> 패키지)</li>
<li>예외) DataFrame의 .stat 속성 이용 (6장 참고)</li>
<li>스칼라, 파이썬에서 임포트 할 수 있는 함수와 SQL에서 사용가능한 함수는 약간 다름 (매 릴리즈마다 조금씩 변함)</li>
</ul>
</li>
</ul>
<h4 id="집계-함수"><a href="#집계-함수" class="headerlink" title="집계 함수"></a>집계 함수</h4><blockquote>
<p>집계 함수 : 키나 그룹을 지정하고 + 하나 이상의 컬럼을 변환하는 방법을 지정 (여러 입력값이 주어지면 그룹 별로 결과 생성)</p>
<ul>
<li>수치형 데이터 요약 (ex. 그룹의 평균값 구하기)</li>
<li>합산, 곱셈, 카운팅 등의 작업</li>
<li>복합 데이터 타입(배열, 리스트, 맵)을 사용한 집계 수행 가능 </li>
</ul>
</blockquote>
<ul>
<li><p><code>count(컬럼명)</code> : 전체 로우 수 카운트</p>
<ul>
<li><p>액션이 아닌 <strong>트랜스포메이션</strong>으로 동작</p>
</li>
<li><p>두가지 방식으로 사용 가능</p>
<ul>
<li><code>count(특정 컬럼)</code> : null 값 포함 X</li>
<li><code>count(*)</code> or <code>count(1)</code> : null 값 가진 로우 포함해서 카운트</li>
</ul>
</li>
<li><details><summary class="only-hover">[7.1.1] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.count</span><br><span class="line">df.select(count(<span class="string">&quot;StockCode&quot;</span>)).show() <span class="comment">// 541909</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> dfTable</span><br></pre></td></tr></table></figure>
</details>
</li>
</ul>
</li>
<li><p><code>countDistinct(컬럼명)</code> : 고유 (distinct) 레코드 수 카운트</p>
<ul>
<li><details><summary class="only-hover">[7.1.2] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.countDistinct</span><br><span class="line">df.select(countDistinct(<span class="string">&quot;StockCode&quot;</span>)).show() <span class="comment">// 4070</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> <span class="operator">*</span>) <span class="keyword">FROM</span> DFTABLE</span><br></pre></td></tr></table></figure>
</details>
</li>
</ul>
</li>
<li><p><code>approx_count_distinct(컬럼명, 최대추정오류율)</code> : 근사치 고유 레코드 수 카운트</p>
<ul>
<li><p>대규모 데이터셋 다룰 시 정확한 개수 무의미함 =&gt; 근사치로 효율</p>
</li>
<li><p><code>최대 추정 오류율 (maximum estimation error)</code> 파라미터 설정</p>
</li>
<li><details><summary class="only-hover">[7.1.3] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.approx_count_distinct</span><br><span class="line">df.select(approx_count_distinct(<span class="string">&quot;StockCode&quot;</span>, <span class="number">0.1</span>)).show() <span class="comment">// 3364</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> approx_count_distinct(StockCode, <span class="number">0.1</span>) <span class="keyword">FROM</span> DFTABLE</span><br></pre></td></tr></table></figure>

</details>


</li>
</ul>
</li>
</ul>
<ul>
<li><p><code>first(컬럼명)</code>, <code>last(컬럼명)</code> : 첫 번째 값, 마지막 값 추출</p>
<ul>
<li><p>DataFrame 값이 아닌 로우 기반 동작</p>
</li>
<li><details><summary class="only-hover">[7.1.4] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df.select(first(<span class="string">&quot;StockCode&quot;</span>), last(<span class="string">&quot;StockCode&quot;</span>)).show()</span><br><span class="line"><span class="comment">// +-----------------------+----------------------+</span></span><br><span class="line"><span class="comment">// |first(StockCode, false)|last(StockCode, false)|</span></span><br><span class="line"><span class="comment">// +-----------------------+----------------------+</span></span><br><span class="line"><span class="comment">// |                 85123A|                 22138|</span></span><br><span class="line"><span class="comment">// +-----------------------+----------------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">first</span>(StockCode), <span class="keyword">last</span>(StockCode) <span class="keyword">FROM</span> dfTable</span><br></pre></td></tr></table></figure>
</details>
</li>
</ul>
</li>
<li><p><code>min(컬럼명)</code>, <code>max(컬럼명)</code> : 최솟값, 최댓값 추출</p>
<ul>
<li><details><summary class="only-hover">[7.1.5] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;min, max&#125;</span><br><span class="line">df.select(min(<span class="string">&quot;Quantity&quot;</span>), max(<span class="string">&quot;Quantity&quot;</span>)).show()</span><br><span class="line"><span class="comment">// +-------------+-------------+</span></span><br><span class="line"><span class="comment">// |min(Quantity)|max(Quantity)|</span></span><br><span class="line"><span class="comment">// +-------------+-------------+</span></span><br><span class="line"><span class="comment">// |       -80995|        80995|</span></span><br><span class="line"><span class="comment">// +-------------+-------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">min</span>(Quantity), <span class="built_in">max</span>(Quantity) <span class="keyword">FROM</span> dfTable</span><br></pre></td></tr></table></figure>
</details>
</li>
</ul>
</li>
<li><p><code>sum(컬럼명)</code> : 특정 컬럼의 모든 값 합산</p>
<ul>
<li><details><summary class="only-hover">[7.1.6] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.sum</span><br><span class="line">df.select(sum(<span class="string">&quot;Quantity&quot;</span>)).show() <span class="comment">// 5176450</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |sum(Quantity)|</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br><span class="line"><span class="comment">// |      5176450|</span></span><br><span class="line"><span class="comment">// +-------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">sum</span>(Quantity) <span class="keyword">FROM</span> dfTable</span><br></pre></td></tr></table></figure>
</details>


</li>
</ul>
</li>
</ul>
<ul>
<li><p><code>sumDistinct(컬럼명)</code> : 특정 컬럼의 고유 (distinct) 값 합산</p>
<ul>
<li><details><summary class="only-hover">[7.1.7] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.sumDistinct</span><br><span class="line">df.select(sumDistinct(<span class="string">&quot;Quantity&quot;</span>)).show() <span class="comment">// 29310</span></span><br><span class="line"><span class="comment">// +----------------------+</span></span><br><span class="line"><span class="comment">// |sum(DISTINCT Quantity)|</span></span><br><span class="line"><span class="comment">// +----------------------+</span></span><br><span class="line"><span class="comment">// |                 29310|</span></span><br><span class="line"><span class="comment">// +----------------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">SUM</span>(Quantity) <span class="keyword">FROM</span> dfTable <span class="comment">-- 29310</span></span><br></pre></td></tr></table></figure>
</details>


</li>
</ul>
</li>
</ul>
<ul>
<li><p><code>avg(컬럼명)</code> : 평균 값</p>
<ul>
<li><p>== <code>sum()/count()</code> == <code>expr(&quot;mean(컬럼명)&quot;)</code></p>
</li>
<li><p>+ <code>distinct()</code> =&gt; 고윳값 평균 구하기도 가능</p>
</li>
<li><details><summary class="only-hover">[7.1.8] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;sum, count, avg, expr&#125;</span><br><span class="line">(df.select(</span><br><span class="line">    count(<span class="string">&quot;Quantity&quot;</span>).alias(<span class="string">&quot;total_transactions&quot;</span>),</span><br><span class="line">    sum(<span class="string">&quot;Quantity&quot;</span>).alias(<span class="string">&quot;total_purchases&quot;</span>),</span><br><span class="line">    avg(<span class="string">&quot;Quantity&quot;</span>).alias(<span class="string">&quot;avg_purchases&quot;</span>),</span><br><span class="line">    expr(<span class="string">&quot;mean(Quantity)&quot;</span>).alias(<span class="string">&quot;mean_purchases&quot;</span>))</span><br><span class="line">  .selectExpr(</span><br><span class="line">    <span class="string">&quot;total_purchases/total_transactions&quot;</span>,</span><br><span class="line">    <span class="string">&quot;avg_purchases&quot;</span>,</span><br><span class="line">    <span class="string">&quot;mean_purchases&quot;</span>).show())</span><br><span class="line"><span class="comment">// +--------------------------------------+----------------+----------------+</span></span><br><span class="line"><span class="comment">// |(total_purchases / total_transactions)|   avg_purchases|  mean_purchases|</span></span><br><span class="line"><span class="comment">// +--------------------------------------+----------------+----------------+</span></span><br><span class="line"><span class="comment">// |                      9.55224954743324|9.55224954743324|9.55224954743324|</span></span><br><span class="line"><span class="comment">// +--------------------------------------+----------------+----------------+</span></span><br></pre></td></tr></table></figure>
</details>
</li>
</ul>
</li>
<li><p>분산과 표준편차</p>
<ul>
<li><p>평균(<code>m</code>) 주변에 데이터가 분포된 정도를 측정</p>
<ul>
<li>분산 : 평균과의 차이를 제곱한 결과의 평균 (<code>v = avg((x-m)^2)</code>)</li>
<li>표준편차 : 분산의 제곱근 (<code>σ = v^(1/2)</code>)</li>
</ul>
</li>
<li><p>스파크는 표본표준편차(sample standard deviation), 모표준편차(population standard deviation) 방식 지원</p>
<ul>
<li>=&gt; 아예 다르므로 <strong>잘 구분해서 사용해야함</strong></li>
</ul>
</li>
<li><p>표본표준분산, 표본표준편차 방식 사용 시 =&gt; <code>variance()</code>, <code>stddev()</code></p>
</li>
<li><p>모표준분산, 모표준편차 방식 사용 시 =&gt; <code>var_pop()</code>, <code>stddev_pop()</code></p>
</li>
<li><details><summary class="only-hover">[7.1.9] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df.select(var_pop(<span class="string">&quot;Quantity&quot;</span>), var_samp(<span class="string">&quot;Quantity&quot;</span>),</span><br><span class="line">  stddev_pop(<span class="string">&quot;Quantity&quot;</span>), stddev_samp(<span class="string">&quot;Quantity&quot;</span>)).show()</span><br><span class="line"><span class="comment">// +-----------------+------------------+--------------------+---------------------+</span></span><br><span class="line"><span class="comment">// |var_pop(Quantity)|var_samp(Quantity)|stddev_pop(Quantity)|stddev_samp(Quantity)|</span></span><br><span class="line"><span class="comment">// +-----------------+------------------+--------------------+---------------------+</span></span><br><span class="line"><span class="comment">// |47559.30364660923| 47559.39140929892|  218.08095663447835|   218.08115785023455|</span></span><br><span class="line"><span class="comment">// +-----------------+------------------+--------------------+---------------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">var_pop</span>(Quantity), <span class="built_in">var_samp</span>(Quantity),</span><br><span class="line"><span class="built_in">stddev_pop</span>(Quantity), <span class="built_in">stddev_samp</span>(Quantity)</span><br><span class="line"><span class="keyword">FROM</span> dfTable</span><br></pre></td></tr></table></figure>
</details>
</li>
</ul>
</li>
<li><p>비대칭도와 첨도</p>
<ul>
<li><p>데이터의 변곡점(extreme point) 를 측정하는 방법</p>
<ul>
<li><code>skewness(컬럼명)</code> : 비대칭도 (데이터 평균의 비대칭 정도) 측정</li>
<li><code>kurtosis(컬럼명)</code> : 첨도 (데이터 끝 부분의 뾰족한 정도) 측정</li>
</ul>
</li>
<li><p>확률변수(random variable)의 확률분포(probability distribution)로 데이터 모델링 시에 중요</p>
</li>
<li><p>수학적인 내용은 따로 알아서… 흠흠..</p>
</li>
<li><details><summary class="only-hover">[7.1.10] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;skewness, kurtosis&#125;</span><br><span class="line">df.select(skewness(<span class="string">&quot;Quantity&quot;</span>), kurtosis(<span class="string">&quot;Quantity&quot;</span>)).show()</span><br><span class="line"><span class="comment">// +--------------------+------------------+</span></span><br><span class="line"><span class="comment">// |  skewness(Quantity)|kurtosis(Quantity)|</span></span><br><span class="line"><span class="comment">// +--------------------+------------------+</span></span><br><span class="line"><span class="comment">// |-0.26407557610528376|119768.05495530753|</span></span><br><span class="line"><span class="comment">// +--------------------+------------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> skewness(Quantity), kurtosis(Quantity) <span class="keyword">FROM</span> dfTable</span><br></pre></td></tr></table></figure>
</details>
</li>
</ul>
</li>
<li><p>공분산과 상관관계</p>
<ul>
<li><p>두 컬럼값 사이의 영향도 비교</p>
</li>
<li><p><code>cov(컬럼1, 컬럼2)</code> : 공분산(covariance) 계산</p>
<ul>
<li>데이터 입력값에 따라 다른 범위를 가짐</li>
<li>var 함수처럼 표본공분산(sample covariance)이나 모공분산(population covariance) 방식으로도 계산 가능 =&gt; <code>covar_samp()</code>, <code>covar_pop()</code></li>
</ul>
</li>
<li><p><code>corr(컬럼1, 컬럼2)</code> : 상관관계(correlation) 계산</p>
<ul>
<li>피어슨 상관계수 (Pearson correlation coefficient) 측정 (-1 &lt;= <code>r</code> &lt;= 1)</li>
<li>모집단이나 표본에 대한 계산 개념 X</li>
</ul>
</li>
<li><details><summary class="only-hover">[7.1.11] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;corr, covar_pop, covar_samp&#125;</span><br><span class="line">df.select(corr(<span class="string">&quot;InvoiceNo&quot;</span>, <span class="string">&quot;Quantity&quot;</span>), covar_samp(<span class="string">&quot;InvoiceNo&quot;</span>, <span class="string">&quot;Quantity&quot;</span>),</span><br><span class="line">    covar_pop(<span class="string">&quot;InvoiceNo&quot;</span>, <span class="string">&quot;Quantity&quot;</span>)).show()</span><br><span class="line"><span class="comment">// +-------------------------+-------------------------------+------------------------------+</span></span><br><span class="line"><span class="comment">// |corr(InvoiceNo, Quantity)|covar_samp(InvoiceNo, Quantity)|covar_pop(InvoiceNo, Quantity)|</span></span><br><span class="line"><span class="comment">// +-------------------------+-------------------------------+------------------------------+</span></span><br><span class="line"><span class="comment">// |     4.912186085640497E-4|             1052.7280543915997|            1052.7260778754955|</span></span><br><span class="line"><span class="comment">// +-------------------------+-------------------------------+------------------------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">corr</span>(InvoiceNo, Quantity), <span class="built_in">covar_samp</span>(InvoiceNo, Quantity),</span><br><span class="line"><span class="built_in">covar_pop</span>(InvoiceNo, Quantity)</span><br><span class="line"><span class="keyword">FROM</span> dfTable</span><br></pre></td></tr></table></figure>
</details>
</li>
</ul>
</li>
<li><p>복합 데이터 타입의 집계</p>
<ul>
<li><p>스파크는 수식을 통한 집계 외에도 <strong>복합 데이터 타입</strong>을 사용한 집계 가능 (ex. 특정 컬럼 값 =&gt; List, Set .. 등으로 수집)</p>
</li>
<li><p>수집된 데이터는 다양한 프로그래밍 방식으로 다루거나 활용 가능</p>
</li>
<li><details><summary class="only-hover">[7.1.12] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;collect_set, collect_list&#125;</span><br><span class="line">df.agg(collect_set(<span class="string">&quot;Country&quot;</span>), collect_list(<span class="string">&quot;Country&quot;</span>)).show()</span><br><span class="line"><span class="comment">// +--------------------+---------------------+</span></span><br><span class="line"><span class="comment">// |collect_set(Country)|collect_list(Country)|</span></span><br><span class="line"><span class="comment">// +--------------------+---------------------+</span></span><br><span class="line"><span class="comment">// |[Portugal, Italy,...| [United Kingdom, ...|</span></span><br><span class="line"><span class="comment">// +--------------------+---------------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> collect_set(Country), collect_set(Country) <span class="keyword">FROM</span> dfTable</span><br></pre></td></tr></table></figure>
</details>

</li>
</ul>
</li>
</ul>
<h3 id="7-2-그룹화"><a href="#7-2-그룹화" class="headerlink" title="7.2 그룹화"></a>7.2 그룹화</h3><ul>
<li><u>데이터 <strong>그룹</strong> 기반의 집계</u> 에 대한 내용<ul>
<li>([7.1] 은 DataFrame 수준의 집계 내용)</li>
<li>카테고리형 데이터(categorical data) 사용</li>
<li>=&gt; 단일 컬럼의 데이터를 그룹화, 해당 그룹의 다른 여러 컬럼을 사용해서 계산</li>
</ul>
</li>
<li>그룹화 작업의 2 단계<ul>
<li>1) 하나 이상의 컬럼 그룹화 (여러개 지정도 가능)</li>
<li>2) 집계 연산 수행</li>
</ul>
</li>
<li>표현식을 이용한 그룹화<ul>
<li>카운팅은 메서드, 함수 둘 다 사용 가능 🤔<ul>
<li>메서드 보다 <code>count()</code> 함수 사용 추천</li>
<li>select 구문의 표현식 지정보다 <code>agg()</code> 메서드 사용 추천</li>
</ul>
</li>
<li><code>agg()</code> : 여러 집계 처리 한번에 지정 &amp; 집계에 표현식 사용 가능<ul>
<li>트랜스포메이션 완료 컬럼에 <code>alias</code> 사용 가능</li>
</ul>
</li>
</ul>
</li>
<li>맵을 이용한 그룹화<ul>
<li>맵(map) 타입 사용 : Key = 컬럼 / Value = 수행할 집계 함수의 문자열</li>
<li>수행할 집계함수를 한 줄로 작성 시 =&gt; 여러 컬럼명 재사용 가능<ul>
<li><code>agg(Key -&gt; Value, Key -&gt; Value, ...)</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="7-3-윈도우-함수"><a href="#7-3-윈도우-함수" class="headerlink" title="7.3 윈도우 함수"></a>7.3 윈도우 함수</h3><ul>
<li><strong>윈도우 함수</strong> 도 집계에 사용 가능</li>
<li>윈도우 함수<ul>
<li>데이터의 특정 ‘윈도우(window)’ 대상으로 고유의 집계 연산 수행</li>
<li>데이터의 ‘윈도우’ =&gt; 현재 데이터에 대한 참조(reference)를 사용해 정의</li>
<li>윈도우 명세(window specification) =&gt; 함수에 전달될 로우 결정</li>
</ul>
</li>
<li>스파크가 지원하는 윈도우 함수<ul>
<li>랭크 함수 (ranking function)</li>
<li>분석 함수 (analytic function)</li>
<li>집계 함수 (aggragate function)</li>
</ul>
</li>
<li>윈도우 함수 vs group-by 함수<ul>
<li>윈도우 함수 : <strong>프레임</strong>에 입력되는 모든 로우에 대해 결과값 계산</li>
<li>group-by 함수 : 모든 로우 레코드가 단일 그룹으로만 이동</li>
</ul>
</li>
<li>프레임(frame) : 로우 그룹 기반의 테이블<ul>
<li>각 로우는 하나 이상의 프레임에 할당 가능<img width="300" alt="row - window frame" src="https://user-images.githubusercontent.com/26691216/106770674-8b5eeb00-6681-11eb-929f-09e7c373f9a2.png"></li>
<li>프레임 정의 방법은 예제 참고</li>
</ul>
</li>
<li>ex. 하루를 나타내는 값의 롤링 평균(rolling average) 구하기<ul>
<li>개별 로우가 7개의 다른 프레임으로 구성되어야 함</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">[7.3] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1) 주문 일자(InvoiceDate) =&gt; &#x27;date&#x27; 컬럼으로 변환 (날짜 정보만 포함)</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;col, to_date&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> dfWithDate = df.withColumn(<span class="string">&quot;date&quot;</span>, to_date(col(<span class="string">&quot;InvoiceDate&quot;</span>),</span><br><span class="line">  <span class="string">&quot;MM/d/yyyy H:mm&quot;</span>))</span><br><span class="line">dfWithDate.createOrReplaceTempView(<span class="string">&quot;dfWithDate&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 2) 윈도우 명세 만들기</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.col</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> windowSpec = (<span class="type">Window</span></span><br><span class="line">  .partitionBy(<span class="string">&quot;CustomerId&quot;</span>, <span class="string">&quot;date&quot;</span>)  <span class="comment">// 그룹을 어떻게 나눌지 결정</span></span><br><span class="line">  .orderBy(col(<span class="string">&quot;Quantity&quot;</span>).desc)    <span class="comment">// 파티션 정렬 방식</span></span><br><span class="line">  .rowsBetween(<span class="type">Window</span>.unboundedPreceding, <span class="type">Window</span>.currentRow)) <span class="comment">// 프레임 명세 (=&gt; 첫 로우 ~ 현재 로우까지 확인)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 3) 집계 함수로 분석</span></span><br><span class="line"><span class="comment">// =&gt; 컬럼 or 표현식 반환 시 DataFrame.select() 에서 사용 가능</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 예시 1. maxPurchaseQuantity = 시간대별 최대 구매 개수</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.max</span><br><span class="line"><span class="keyword">val</span> maxPurchaseQuantity = max(col(<span class="string">&quot;Quantity&quot;</span>)).over(windowSpec)</span><br><span class="line"><span class="comment">// maxPurchaseQuantity: org.apache.spark.sql.Column = max(Quantity) OVER (PARTITION BY CustomerId, date ORDER BY Quantity DESC NULLS LAST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 예시 2. purchase(Dense)Rank = 구매량 순위 </span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;dense_rank, rank&#125;</span><br><span class="line"><span class="keyword">val</span> purchaseDenseRank = dense_rank().over(windowSpec) <span class="comment">// 순위가 비지않도록 dense_rank() 사용</span></span><br><span class="line"><span class="keyword">val</span> purchaseRank = rank().over(windowSpec)</span><br><span class="line"></span><br><span class="line"><span class="comment">// DataFrame.select()로 윈도우 값 확인</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.col</span><br><span class="line"></span><br><span class="line">(dfWithDate.where(<span class="string">&quot;CustomerId IS NOT NULL&quot;</span>).orderBy(<span class="string">&quot;CustomerId&quot;</span>)</span><br><span class="line">  .select(</span><br><span class="line">    col(<span class="string">&quot;CustomerId&quot;</span>),</span><br><span class="line">    col(<span class="string">&quot;date&quot;</span>),</span><br><span class="line">    col(<span class="string">&quot;Quantity&quot;</span>),</span><br><span class="line">    purchaseRank.alias(<span class="string">&quot;quantityRank&quot;</span>),</span><br><span class="line">    purchaseDenseRank.alias(<span class="string">&quot;quantityDenseRank&quot;</span>),</span><br><span class="line">    maxPurchaseQuantity.alias(<span class="string">&quot;maxPurchaseQuantity&quot;</span>)).show())</span><br><span class="line"><span class="comment">// +----------+----------+--------+------------+-----------------+-------------------+</span></span><br><span class="line"><span class="comment">// |CustomerId|      date|Quantity|quantityRank|quantityDenseRank|maxPurchaseQuantity|</span></span><br><span class="line"><span class="comment">// +----------+----------+--------+------------+-----------------+-------------------+</span></span><br><span class="line"><span class="comment">// |     12346|2011-01-18|   74215|           1|                1|              74215|</span></span><br><span class="line"><span class="comment">// |     12346|2011-01-18|  -74215|           2|                2|              74215|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      36|           1|                1|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      30|           2|                2|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      24|           3|                3|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|      12|           4|                4|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|       6|          17|                5|                 36|</span></span><br><span class="line"><span class="comment">// |     12347|2010-12-07|       6|          17|                5|                 36|</span></span><br><span class="line"><span class="comment">// +----------+----------+--------+------------+-----------------+-------------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- SQL</span></span><br><span class="line"><span class="keyword">SELECT</span> CustomerId, <span class="type">date</span>, Quantity,</span><br><span class="line">  <span class="built_in">rank</span>(Quantity) <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> CustomerId, <span class="type">date</span></span><br><span class="line">                       <span class="keyword">ORDER</span> <span class="keyword">BY</span> Quantity <span class="keyword">DESC</span> <span class="keyword">NULLS</span> <span class="keyword">LAST</span></span><br><span class="line">                       <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span></span><br><span class="line">                         UNBOUNDED PRECEDING <span class="keyword">AND</span></span><br><span class="line">                         <span class="keyword">CURRENT</span> <span class="type">ROW</span>) <span class="keyword">as</span> rank,</span><br><span class="line"></span><br><span class="line">  <span class="built_in">dense_rank</span>(Quantity) <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> CustomerId, <span class="type">date</span></span><br><span class="line">                             <span class="keyword">ORDER</span> <span class="keyword">BY</span> Quantity <span class="keyword">DESC</span> <span class="keyword">NULLS</span> <span class="keyword">LAST</span></span><br><span class="line">                             <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span></span><br><span class="line">                               UNBOUNDED PRECEDING <span class="keyword">AND</span></span><br><span class="line">                               <span class="keyword">CURRENT</span> <span class="type">ROW</span>) <span class="keyword">as</span> dRank,</span><br><span class="line"></span><br><span class="line">  <span class="built_in">max</span>(Quantity) <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> CustomerId, <span class="type">date</span></span><br><span class="line">                      <span class="keyword">ORDER</span> <span class="keyword">BY</span> Quantity <span class="keyword">DESC</span> <span class="keyword">NULLS</span> <span class="keyword">LAST</span></span><br><span class="line">                      <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span></span><br><span class="line">                        UNBOUNDED PRECEDING <span class="keyword">AND</span></span><br><span class="line">                        <span class="keyword">CURRENT</span> <span class="type">ROW</span>) <span class="keyword">as</span> maxPurchase</span><br><span class="line"><span class="keyword">FROM</span> dfWithDate <span class="keyword">WHERE</span> CustomerId <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> CustomerId</span><br></pre></td></tr></table></figure>
</details>

<blockquote>
<p>Window 메서드</p>
<ul>
<li><code>partitionBy()</code> : 그룹을 어떻게 나눌지 결정 (지금까지 파티셔닝 스키마 개념이랑 관련 X)</li>
<li><code>orderBy()</code> : 파티션 정렬 방식 정의</li>
<li><code>rowsBetween(from, to)</code> : 입력된 로우의 참조 기반으로 프레임에 로우가 포함될 수 있는지 결정</li>
</ul>
<p>row_number vs <strong>rank</strong> vs <strong>dense_rank</strong></p>
<ul>
<li><code>row_number()</code> : 순서대로 넘버링 (1,2,3,4 …)</li>
<li><code>rank()</code> : 순서대로 넘버링 + 같은 값일 경우 같은 숫자 (1,1,3,4 …)</li>
<li><code>dense_rank()</code> : rank 와 동일하되, 빈값 없이 증가하게끔 넘버링 (1,1,2,3, …)</li>
</ul>
</blockquote>
<h3 id="7-4-그룹화-셋"><a href="#7-4-그룹화-셋" class="headerlink" title="7.4 그룹화 셋"></a>7.4 그룹화 셋</h3><ul>
<li>컬럼의 값을 이용해 여러 컬럽 집계 =&gt; <code>group-by</code> 표현식<ul>
<li>그러면 <strong>여러 그룹</strong>에 걸쳐 집계는? =&gt; <strong>그룹화셋</strong>  사용</li>
</ul>
</li>
<li>그룹화 셋 : 여러 집계를 결합하는 저수준 기능<ul>
<li><code>GROUPING SETS</code> 구문은 SQL에서만 사용 가능</li>
<li>DataFrame에서 동일 연산하려면? =&gt; <strong>롤업</strong>, <strong>큐브</strong> 메서드 사용</li>
</ul>
</li>
<li>주의 사항<ul>
<li>그룹화 셋, 롤업, 큐브 사용 시 <strong>null 제거 필수</strong></li>
<li>null에 따라 집계 수준이 달라짐 (=&gt; null 미제거시 부정확한 결과)</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">[7.4.0] '그룹화 셋' 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 그룹화 셋 사용 시 null 제거 필수</span></span><br><span class="line"><span class="keyword">val</span> dfNoNull = dfWithDate.drop()</span><br><span class="line">dfNoNull.createOrReplaceTempView(<span class="string">&quot;dfNoNull&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- SQL 예제 1) 재고 코드(StockCode)와 고객(CustomerId) 별 총 수량 구하기</span></span><br><span class="line"><span class="keyword">SELECT</span> CustomerId, stockCode, <span class="built_in">sum</span>(Quantity) <span class="keyword">FROM</span> dfNoNull</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> customerId, stockCode</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> CustomerId <span class="keyword">DESC</span>, stockCode <span class="keyword">DESC</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- (그룹화 셋 사용한 동일 표현)</span></span><br><span class="line"><span class="keyword">SELECT</span> CustomerId, stockCode, <span class="built_in">sum</span>(Quantity) <span class="keyword">FROM</span> dfNoNull</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> customerId, stockCode <span class="keyword">GROUPING</span> <span class="keyword">SETS</span>((customerId, stockCode))</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> CustomerId <span class="keyword">DESC</span>, stockCode <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- SQL 예제 2) 예제 1 + 재고 코드나 고객 상관없이 총 수량 합산 결과 추가 =&gt; group-by로 처리 불가</span></span><br><span class="line"><span class="comment">-- 그룹화 셋으로 집계 방식 지정</span></span><br><span class="line"><span class="keyword">SELECT</span> CustomerId, stockCode, <span class="built_in">sum</span>(Quantity) <span class="keyword">FROM</span> dfNoNull</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> customerId, stockCode <span class="keyword">GROUPING</span> <span class="keyword">SETS</span>((customerId, stockCode),())</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> CustomerId <span class="keyword">DESC</span>, stockCode <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># output</span></span><br><span class="line">+----------+---------+-------------+</span><br><span class="line">|CustomerId|stockCode|sum(Quantity)|</span><br><span class="line">+----------+---------+-------------+</span><br><span class="line">|     18287|    85173|           48|</span><br><span class="line">|     18287|   85040A|           48|</span><br><span class="line">|     18287|   85039B|          120|</span><br><span class="line">...</span><br><span class="line">|     18287|    23269|           36|</span><br><span class="line">+----------+---------+-------------+</span><br></pre></td></tr></table></figure>
</details>

<ul>
<li>롤업(rollup)<ul>
<li><code>group-by</code> 스타일의 다양한 연산을 수행할 수 있는 다차원 집계 기능</li>
<li><code>rollup(그룹화 키)</code> =&gt; 다양한 컬럼을 그룹화 키로 설정 가능</li>
<li>롤업된 컬럼값이 모두 null 인 로우 = 해당 컬럼에 속한 레코드의 전체 합계</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">[7.4.1] '롤업' 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 시간(신규 Date 컬럼), 공간(Country) 을 축으로 하는 롤업</span></span><br><span class="line"><span class="comment">// =&gt; &#x27;모든 날짜 총합&#x27;, &#x27;날짜별 총합&#x27;, &#x27;날짜별 국가별 총합&#x27; 포함하는 DataFrame 생성</span></span><br><span class="line"><span class="keyword">val</span> rolledUpDF = (dfNoNull.rollup(<span class="string">&quot;Date&quot;</span>, <span class="string">&quot;Country&quot;</span>).agg(sum(<span class="string">&quot;Quantity&quot;</span>))</span><br><span class="line">  .selectExpr(<span class="string">&quot;Date&quot;</span>, <span class="string">&quot;Country&quot;</span>, <span class="string">&quot;`sum(Quantity)` as total_quantity&quot;</span>)</span><br><span class="line">  .orderBy(<span class="string">&quot;Date&quot;</span>))</span><br><span class="line">rolledUpDF.show()</span><br><span class="line"><span class="comment">// +----------+--------------+--------------+</span></span><br><span class="line"><span class="comment">// |      Date|       Country|total_quantity|</span></span><br><span class="line"><span class="comment">// +----------+--------------+--------------+</span></span><br><span class="line"><span class="comment">// |      null|          null|       5176450| =&gt; 전체 합계</span></span><br><span class="line"><span class="comment">// |2010-12-01|   Netherlands|            97|</span></span><br><span class="line"><span class="comment">// |2010-12-01|       Germany|           117|</span></span><br><span class="line"><span class="comment">// |2010-12-01|     Australia|           107|</span></span><br><span class="line"><span class="comment">// |2010-12-01|        France|           449|</span></span><br><span class="line"><span class="comment">// |2010-12-01|          EIRE|           243|</span></span><br><span class="line"><span class="comment">// |2010-12-01|United Kingdom|         23949|</span></span><br><span class="line"><span class="comment">// |2010-12-01|          null|         26814|</span></span><br><span class="line"><span class="comment">// |2010-12-01|        Norway|          1852|</span></span><br><span class="line"><span class="comment">// |2010-12-02|          EIRE|             4|</span></span><br><span class="line"><span class="comment">// |2010-12-02|          null|         21023|</span></span><br><span class="line"><span class="comment">// |2010-12-02|       Germany|           146|</span></span><br><span class="line"><span class="comment">// |2010-12-02|United Kingdom|         20873|</span></span><br><span class="line"><span class="comment">// |2010-12-03|        France|           239|</span></span><br><span class="line"><span class="comment">// |2010-12-03|      Portugal|            65|</span></span><br><span class="line"><span class="comment">// |2010-12-03|       Germany|           170|</span></span><br><span class="line"><span class="comment">// |2010-12-03|       Belgium|           528|</span></span><br><span class="line"><span class="comment">// |2010-12-03|         Spain|           400|</span></span><br><span class="line"><span class="comment">// |2010-12-03|         Italy|           164|</span></span><br><span class="line"><span class="comment">// |2010-12-03|   Switzerland|           110|</span></span><br><span class="line"><span class="comment">// +----------+--------------+--------------+</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// Country, Date 둘 다 null 인 로우 =&gt; 전체 합계 나타냄</span></span><br><span class="line">rolledUpDF.where(<span class="string">&quot;Country IS NULL&quot;</span>).show()</span><br><span class="line">rolledUpDF.where(<span class="string">&quot;Date IS NULL&quot;</span>).show()</span><br><span class="line"><span class="comment">// +----+-------+--------------+</span></span><br><span class="line"><span class="comment">// |Date|Country|total_quantity|</span></span><br><span class="line"><span class="comment">// +----+-------+--------------+</span></span><br><span class="line"><span class="comment">// |null|   null|       5176450|</span></span><br><span class="line"><span class="comment">// +----+-------+--------------+</span></span><br></pre></td></tr></table></figure>
</details>

<ul>
<li>큐브(cube)<ul>
<li>롤업의 고차원적 사용 (호출 방식도 유사)</li>
<li>요소들을 계층적으로 다루는 대신 모든 차원에 대해 동일한 작업 수행</li>
<li>ex. 전체 기간에 대한 날짜와 국가별 결과 구하기</li>
<li><code>cube(그룹화 키)</code> =&gt; 요약 정보 테이블 만들기 가능</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">[7.4.2] '큐브' 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 시간(신규 Date 컬럼), 공간(Country) 을 축으로 하는 큐브</span></span><br><span class="line"><span class="comment">// =&gt; &#x27;전체 기간에 대한 날짜와 국가별 결과&#x27; 포함하는 DataFrame 생성</span></span><br><span class="line"><span class="comment">//     (외에도 전체 날짜와 모든 국가에 대한 합계, 모든 국가의 날짜별 합계, 날짜별 국가별 합계, 전체 날짜의 국가별 합계, ... 가능)</span></span><br><span class="line">(dfNoNull.cube(<span class="string">&quot;Date&quot;</span>, <span class="string">&quot;Country&quot;</span>).agg(sum(col(<span class="string">&quot;Quantity&quot;</span>)))</span><br><span class="line">  .select(<span class="string">&quot;Date&quot;</span>, <span class="string">&quot;Country&quot;</span>, <span class="string">&quot;sum(Quantity)&quot;</span>).orderBy(<span class="string">&quot;Date&quot;</span>).show())</span><br><span class="line"><span class="comment">// +----+--------------------+-------------+</span></span><br><span class="line"><span class="comment">// |Date|             Country|sum(Quantity)|</span></span><br><span class="line"><span class="comment">// +----+--------------------+-------------+</span></span><br><span class="line"><span class="comment">// |null|               Japan|        25218|</span></span><br><span class="line"><span class="comment">// |null|            Portugal|        16180|</span></span><br><span class="line"><span class="comment">// |null|             Germany|       117448|</span></span><br><span class="line"><span class="comment">// |null|                 RSA|          352|</span></span><br><span class="line"><span class="comment">// |null|           Australia|        83653|</span></span><br><span class="line"><span class="comment">// |null|           Hong Kong|         4769|</span></span><br><span class="line"><span class="comment">// |null|              Cyprus|         6317|</span></span><br><span class="line"><span class="comment">// |null|             Finland|        10666|</span></span><br><span class="line"><span class="comment">// |null|United Arab Emirates|          982|</span></span><br><span class="line"><span class="comment">// |null|                null|      5176450|</span></span><br><span class="line"><span class="comment">// |null|         Unspecified|         3300|</span></span><br><span class="line"><span class="comment">// |null|               Spain|        26824|</span></span><br><span class="line"><span class="comment">// |null|           Singapore|         5234|</span></span><br><span class="line"><span class="comment">// |null|     Channel Islands|         9479|</span></span><br><span class="line"><span class="comment">// |null|             Lebanon|          386|</span></span><br><span class="line"><span class="comment">// |null|                 USA|         1034|</span></span><br><span class="line"><span class="comment">// |null|             Denmark|         8188|</span></span><br><span class="line"><span class="comment">// |null|              Norway|        19247|</span></span><br><span class="line"><span class="comment">// |null|      Czech Republic|          592|</span></span><br><span class="line"><span class="comment">// |null|  European Community|          497|</span></span><br><span class="line"><span class="comment">// +----+--------------------+-------------+</span></span><br></pre></td></tr></table></figure>
</details>

<ul>
<li>그룹화 메타데이터<ul>
<li>큐브, 롤업 사용 시 집계 수준에 따라 쉽게 필터링하고자 하면 =&gt; <strong>집계 수준 조회</strong> 필요</li>
<li><code>grouping_id()</code> : 결과 데이터셋의 집계 수준을 명시하는 컬럼 제공</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">[7.4.3] grouping_id() 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.&#123;grouping_id, sum, expr&#125;</span><br><span class="line"></span><br><span class="line">(dfNoNull.cube(<span class="string">&quot;customerId&quot;</span>, <span class="string">&quot;stockCode&quot;</span>).agg(grouping_id(), sum(<span class="string">&quot;Quantity&quot;</span>))</span><br><span class="line">.orderBy(col(<span class="string">&quot;grouping_id()&quot;</span>).desc)</span><br><span class="line">.show())</span><br><span class="line"><span class="comment">// =&gt; 4개의 개별 그룹화 ID 값 (0,1,2,3) 반환됨</span></span><br><span class="line"><span class="comment">// +----------+---------+-------------+-------------+</span></span><br><span class="line"><span class="comment">// |customerId|stockCode|grouping_id()|sum(Quantity)|</span></span><br><span class="line"><span class="comment">// +----------+---------+-------------+-------------+</span></span><br><span class="line"><span class="comment">// |      null|     null|            3|      5176450| =&gt; 3 : 가장 높은 계층의 집계 결과. 전체 총 수량 (customerId, stockCode 관계 X)</span></span><br><span class="line"><span class="comment">// |      null|    84226|            2|           17| =&gt; 2 : 개별 stockCode 별 총 수량 (customerId 관계 X)</span></span><br><span class="line"><span class="comment">// |      null|    22856|            2|          518|</span></span><br><span class="line"><span class="comment">// |      null|    22352|            2|         3077|</span></span><br><span class="line"><span class="comment">//            ...</span></span><br><span class="line"><span class="comment">// |     14907|     null|            1|         1686| =&gt; 1 : customerId 기반 총 수량 제공 (구매 물품 관계 X)</span></span><br><span class="line"><span class="comment">// |     14543|     null|            1|          600|</span></span><br><span class="line"><span class="comment">//            ...</span></span><br><span class="line"><span class="comment">// |     13047|    22749|            0|           12| =&gt; 0 : customerId - stockCode 별 조합에 따라 총 수량</span></span><br><span class="line"><span class="comment">// |     15311|    22083|            0|          169|</span></span><br><span class="line"><span class="comment">// +----------+---------+-------------+-------------+</span></span><br></pre></td></tr></table></figure>
</details>

<ul>
<li>피벗(pivot)<ul>
<li><code>pivot()</code> : 로우 → 컬럼으로 변환 가능</li>
<li>=&gt; 컬럼의 모든 값을 단일 그룹화하여 계산 가능<ul>
<li>그러나 데이터 탐색방식에 따라 피벗 수행 결과값이 감소할 수 있음</li>
</ul>
</li>
<li>특정 컬럼 cardinality가 낮으면 피벗으로 다수 컬럼으로 변환 추천   =&gt; 스키마, 쿼리 대상 확인 가능</li>
</ul>
</li>
</ul>
<details><summary class="point-color-can-hover">[7.4.4] '피벗' 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> pivoted = dfWithDate.groupBy(<span class="string">&quot;date&quot;</span>).pivot(<span class="string">&quot;Country&quot;</span>).sum() <span class="comment">// 집계 수행 =&gt; 수치형 컬럼으로 나옴</span></span><br><span class="line"><span class="comment">// pivoted.printSchema()</span></span><br><span class="line"><span class="comment">// root</span></span><br><span class="line"><span class="comment">//  |-- date: date (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Australia_sum(Quantity): long (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Australia_sum(UnitPrice): double (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Australia_sum(CustomerID): long (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Austria_sum(Quantity): long (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Austria_sum(UnitPrice): double (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Austria_sum(CustomerID): long (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Bahrain_sum(Quantity): long (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Bahrain_sum(UnitPrice): double (nullable = true)</span></span><br><span class="line"><span class="comment">//  |-- Bahrain_sum(CustomerID): long (nullable = true)</span></span><br><span class="line"><span class="comment">//  ...</span></span><br><span class="line"></span><br><span class="line">pivoted.where(<span class="string">&quot;date &gt; &#x27;2011-12-05&#x27;&quot;</span>).select(<span class="string">&quot;date&quot;</span> ,<span class="string">&quot;`USA_sum(Quantity)`&quot;</span>).show()</span><br><span class="line"><span class="comment">// +----------+-----------------+</span></span><br><span class="line"><span class="comment">// |      date|USA_sum(Quantity)|</span></span><br><span class="line"><span class="comment">// +----------+-----------------+</span></span><br><span class="line"><span class="comment">// |2011-12-06|             null|</span></span><br><span class="line"><span class="comment">// |2011-12-09|             null|</span></span><br><span class="line"><span class="comment">// |2011-12-08|             -196|</span></span><br><span class="line"><span class="comment">// |2011-12-07|             null|</span></span><br><span class="line"><span class="comment">// +----------+-----------------+</span></span><br></pre></td></tr></table></figure>
</details>

<h3 id="7-5-사용자-정의-집계-함수"><a href="#7-5-사용자-정의-집계-함수" class="headerlink" title="7.5 사용자 정의 집계 함수"></a>7.5 사용자 정의 집계 함수</h3><ul>
<li>사용자 정의 집계 함수 (<strong>UDAF</strong>, user-defined aggregation function)<ul>
<li>직접 제작한 함수나 비즈니스 규칙에 기반한 자체 집계 함수 정의 방법</li>
<li>UDAF 사용 =&gt; 입력 데이터 그룹에 직접 개발한 연산 수행 가능</li>
<li>스파크는 입력 데이터의 모든 그룹 중간 결과를 단일 AggregationBuffer에 저장/관리</li>
</ul>
</li>
<li>UDAF는 현재 스칼라, 자바로만 사용 가능<ul>
<li>Spark 2.3 에서는 UDF/UDAF =&gt; 함수 등록 가능 ([6.12] 참고)</li>
</ul>
</li>
<li>생성 방법<ul>
<li>기본 클래스 UserDefinedAggregateFunction 상속 + 메서드 정의</li>
</ul>
</li>
</ul>
<blockquote>
<p>UDAF 생성 시 정의해야할 메서드</p>
<ul>
<li>inputScheme : <code>UDAF 입력 파라미터의 스키마</code>를 StructType 로 정의</li>
<li>bufferSchema : <code>UDAF 중간 결과의 스키마</code>를 StructType 로 정의</li>
<li>dataType : <code>반환될 값의 DataType</code> 정의</li>
<li>deterministic : <code>UDAF가 동일한 입력값에 대해 항상 동일한 결과를 반환하는지</code> Boolean 값으로 정의</li>
<li>initialize : <code>집계용 버퍼 값 초기화 로직</code> 정의</li>
<li>update : 입력받은 로우 기반으로 <code>내부 버퍼 업데이트 로직</code> 정의</li>
<li>merge : 두 개의 <code>집계용 버퍼 병합 로직</code> 정의</li>
<li>evaluate : <code>집계 최종 결과 생성 로직</code> 정의</li>
</ul>
</blockquote>
<details><summary class="point-color-can-hover">[7.5] 예제 펼치기</summary>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// UDAF 예제 - &#x27;BoolAnd&#x27; Class : 입력된 모든 로우의 컬럼이 true인지 판단</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BoolAnd</span> <span class="keyword">extends</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">sql</span>.<span class="title">expressions</span>.<span class="title">UserDefinedAggregateFunction</span> </span>&#123;</span><br><span class="line">  <span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">StructType</span>, <span class="type">StructField</span>, <span class="type">BooleanType</span>, <span class="type">DataType</span>&#125;</span><br><span class="line">  <span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">MutableAggregationBuffer</span></span><br><span class="line">  <span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">inputSchema</span></span>: org.apache.spark.sql.types.<span class="type">StructType</span> =</span><br><span class="line">    <span class="type">StructType</span>(<span class="type">StructField</span>(<span class="string">&quot;value&quot;</span>, <span class="type">BooleanType</span>) :: <span class="type">Nil</span>)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">bufferSchema</span></span>: <span class="type">StructType</span> = <span class="type">StructType</span>(</span><br><span class="line">    <span class="type">StructField</span>(<span class="string">&quot;result&quot;</span>, <span class="type">BooleanType</span>) :: <span class="type">Nil</span></span><br><span class="line">  )</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">dataType</span></span>: <span class="type">DataType</span> = <span class="type">BooleanType</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">deterministic</span></span>: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">initialize</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    buffer(<span class="number">0</span>) = <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">update</span></span>(buffer: <span class="type">MutableAggregationBuffer</span>, input: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    buffer(<span class="number">0</span>) = buffer.getAs[<span class="type">Boolean</span>](<span class="number">0</span>) &amp;&amp; input.getAs[<span class="type">Boolean</span>](<span class="number">0</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(buffer1: <span class="type">MutableAggregationBuffer</span>, buffer2: <span class="type">Row</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    buffer1(<span class="number">0</span>) = buffer1.getAs[<span class="type">Boolean</span>](<span class="number">0</span>) &amp;&amp; buffer2.getAs[<span class="type">Boolean</span>](<span class="number">0</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span></span>(buffer: <span class="type">Row</span>): <span class="type">Any</span> = &#123;</span><br><span class="line">    buffer(<span class="number">0</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 함수로 등록 및 사용</span></span><br><span class="line"><span class="keyword">val</span> ba = <span class="keyword">new</span> <span class="type">BoolAnd</span></span><br><span class="line">spark.udf.register(<span class="string">&quot;booland&quot;</span>, ba)</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">(spark.range(<span class="number">1</span>)</span><br><span class="line">  .selectExpr(<span class="string">&quot;explode(array(TRUE, TRUE, TRUE)) as t&quot;</span>)</span><br><span class="line">  .selectExpr(<span class="string">&quot;explode(array(TRUE, FALSE, TRUE)) as f&quot;</span>, <span class="string">&quot;t&quot;</span>)</span><br><span class="line">  .select(ba(col(<span class="string">&quot;t&quot;</span>)), expr(<span class="string">&quot;booland(f)&quot;</span>))</span><br><span class="line">  .show())</span><br><span class="line"><span class="comment">// +----------+----------+</span></span><br><span class="line"><span class="comment">// |booland(t)|booland(f)|</span></span><br><span class="line"><span class="comment">// +----------+----------+</span></span><br><span class="line"><span class="comment">// |      true|     false|</span></span><br><span class="line"><span class="comment">// +----------+----------+</span></span><br></pre></td></tr></table></figure>
</details>


<h3 id="7-6-정리"><a href="#7-6-정리" class="headerlink" title="7.6 정리"></a>7.6 정리</h3><ul>
<li>스파크에서 사용 가능한 여러 유형의 집계 연산</li>
<li>그룹화, 윈도우 함수, 롤업, 큐브</li>
</ul>
<h3 id="📒-단어장"><a href="#📒-단어장" class="headerlink" title="📒 단어장"></a>📒 단어장</h3><ul>
<li>비대칭도(skewness) : 실숫값 확률변수의 확률분포 비대칭성을 나타내는 지표 (=왜도)</li>
<li>첨도(kurtosis) : 확률분포의 뾰족한 정도를 나타내는 척도</li>
</ul>
</div><p class="post-tags"><i class="fa fa-tags" aria-hidden="true"></i><a href="/tags/study/">#study</a><a href="/tags/book/">#book</a><a href="/tags/spark/">#spark</a><a href="/tags/apache/">#apache</a></p></article></div><footer><div class="paginator"><a class="next" href="/2021/02/02/Spark-The-Definitive-Guide-6%EC%9E%A5/">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'minsw-github-io';
var disqus_identifier = '2021/02/03/Spark-The-Definitive-Guide-7장/';
var disqus_title = '&amp;#039;Spark The Definitive Guide&amp;#039; 7장 - 집계해라 애송이';
var disqus_url = 'https://minsw.github.io/2021/02/03/Spark-The-Definitive-Guide-7장/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//#{theme.disqus}.disqus.com/count.js" async></script><div class="copyright"><p>© 2018 - 2021 <a href="https://minsw.github.io">Lukka Min</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-143001954-1",'auto');ga('send','pageview');</script><link rel="stylesheet" href="//cdn.datatables.net/1.10.7/css/jquery.dataTables.min.css" media="screen" type="text/css"><script src="//cdn.datatables.net/1.10.7/js/jquery.dataTables.min.js"></script><script>$(function(){$('.datatable').dataTable( {"order": [[ 0, "desc" ]],"iDisplayLength": -1,"lengthMenu": [[10, 25, 50, -1], [10, 25, 50, "All"]]} );});</script></body></html>